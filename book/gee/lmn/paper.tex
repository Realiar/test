% copyright (c) 1997 Jon Claerbout

\title{Plane waves in three dimensions}
\author{Jon Claerbout}
\label{paper:lmn}
\maketitle

\inputdir{XFig}
In this chapter we seek a deeper understanding
of \bx{plane wave}s in {\it three} dimensions,
where the examples and theory typically refer to functions
of time $t$ and two space coordinates $(x,y)$,
or to 3-D migration images where the $t$
coordinate is depth or traveltime depth.
As in Chapter \ref{paper:pch},
we need to decompose data volumes into subcubes,
shown in Figure \ref{fig:rayab3D}.
\sideplot{rayab3D}{width=3.00in}{
  Left is space of inputs and outputs.
  Right is their separation during analysis.
}

\par
In this chapter we will see that
the wave model implies the 3-D whitener is not a cube filter
but two planar filters.
The wave model allows us to determine
the scale factor of a signal,
even where signals fluctuate in strength because of interference.
Finally, we examine the local-monoplane concept
that uses the superposition principle
to distinguish a sedimentary model cube from a data \bx{cube}.

%\begin{notforlecture}
\section{THE LEVELER:  A VOLUME OR TWO PLANES?}
\sx{leveler}
\par
In {\it two} dimensions,
levelers were taken to be PEFs,
small rectangular planes of numbers in which the time axis
included enough points to include reasonable stepouts were included
and the space axis contained one level plus another space level,
for each plane-wave slope supposed to be present.
\par
We saw that a whitening filter in {\it three} dimensions
is a small volume with shape defined by subroutine 
\texttt{createhelix()}.
%\vpageref{/prog:createhelix_mod}.  % unresolved reference
It might seem natural that the number of points on the $x$-
and $y$-axes be related to the number of plane waves present.
Instead, I assert that if the volume contains plane waves,
we don't want a {\it volume} filter to whiten it;
we can use a {\it pair} of {\it planar} filters to do so
and the order of those filters is the number of planes
thought to be simultaneously present.
I have no firm mathematical proofs,
but I offer you some interesting discussions, examples,
and computer tools for you to experiment with.
It seems that some applications call for the volume filter
while others call for the two planes.
Because two planes of numbers generally contain
many fewer adjustable values than a volume,
statistical-estimation reasons also favor the planes.

\par\noindent
\boxit{
        What is the lowest-order filter that,
        when applied to a volume,
        will destroy
        one and only one slope of plane wave?
        }

\par
First we seek the answer to the question,
``What is the lowest order filter that will destroy
one and only one plane?''
To begin with, we consider that plane to be horizontal
so the volume of numbers is
$f(t,x,y) = b(t)$
where $b(t)$ is an arbitrary function of time.
One filter that has zero-valued output (destroys the plane)
is 
$\partial_x \equiv \partial / \partial x$.
Another is the operator
$\partial_y \equiv \partial / \partial y$.
Still another is the \bx{Laplacian operator} which is
$\partial_{xx}+\partial_{yy}\equiv\partial^2/\partial x^2+\partial^2/\partial y^2$.

\par
The problem with $\partial / \partial x$ is that
although it destroys the required plane,
it also destroys
$f(t,x,y) = a(t,y)$ where $a(t,y)$ is an {\it arbitrary} function of $(t,y)$
such as a cylinder with axis parallel to the $x$-axis.
The operator $\partial / \partial y$ has the same problem
but with the axes rotated.
The Laplacian operator not only destroys our desired plane,
but it also destroys the well known nonplanar function
$e^{ax}\cos(ay)$,
which is just one example of the many other interesting shapes
that constitute solutions to Laplace's equation.
\par
I remind you of a basic fact:
When we set up the fitting goal $\bold 0\approx \bold A \bold f$,
the \bx{quadratic form} minimized is $\bold f\T\bold A\T \bold A \bold f$,
which by differentiation with respect to $\bold f\T$
gives us (in a constraint-free region) $\bold A\T\bold A\bold f = \bold 0$.
So, minimizing the volume integral (actually the sum)
of the squares of the components of the gradient
implies that Laplace's equation is satisfied.

\par
In any volume,
the lowest-order filter
that will destroy level planes and no other wave slope
is a filter that has one input and {\it two outputs}.
That filter is the gradient,
$(\partial / \partial x, \partial / \partial y)$.
Both outputs vanish if and only if
the plane has the proper horizontal orientation.
Other objects and functions are not extinguished
(except for the non-wave-like function $f(t,x,y)= {\rm const}$).
It is annoying that we must deal with {\it two} outputs
and that will be the topic of further discussion.

\par
A wavefield of tilted parallel planes is
$f(t, x,y)= g(\tau -p_x x -p_y y)$, where $g()$ is
an arbitrary one-dimensional function.
The operator that destroys these tilted planes
is the two-component operator
$(\partial_x + p_x \partial_t,\   \partial_y + p_y \partial_t)$.

\par\noindent
\boxit{
\noindent
The operator that destroys a family of dipping planes
$$f(t, x,y) \eq g(\tau -p_x x -p_y y)$$
is
$$
\left[
\begin{array}{c}
        \frac{\partial }{ \partial x} \ +\  p_x \,\frac{\partial }{ \partial t} \\
        \ \\
        \frac{\partial }{ \partial y} \ +\  p_y \,\frac{\partial }{ \partial t} 
\end{array}
\right]
$$
}

\subsection{PEFs overcome spatial aliasing of difference operators}
The problem I found with
finite-difference representations of differential operators
is that they are susceptible to \bx{spatial aliasing}.
Even before they encounter spatial aliasing,
they are susceptible to accuracy problems known
in finite-difference wave propagation as ``frequency dispersion.''
The aliasing problem can be avoided by the use of spatial prediction operators
such as
\begin{equation}
   \begin{array}{cc}
      \cdot &a     \\
      \cdot &b     \\
      1     &c     \\
      \cdot &d     \\
      \cdot &e     \end{array}
\label{eqn:spatialpred}
\end{equation}
where the vertical axis is time;
the horizontal axis is space; and
the ``$\cdot$''s are zeros.
Another possibility is the 2-D whitening filter
\begin{equation}
   \begin{array}{cc}
      f     &a     \\
      g     &b     \\
      1     &c     \\
      \cdot &d     \\
      \cdot &e
      \end{array}
\label{eqn:twoDwhite}
\end{equation}
Imagine all the coefficients vanished but $d=-1$ and the given 1.
Such filters would annihilate the appropriately sloping plane wave.
Slopes that are not exact integers are also approximately extinguishable,
because the adjustable filter coefficients can interpolate in time.
Filters like (\ref{eqn:twoDwhite})
do the operation $\partial_x + p_x \partial_t$,
which is a component of the gradient in the plane of the wavefront,
{\it and}
they include a temporal deconvolution aspect
and a spatial coherency aspect.
My experience shows that the operators (\ref{eqn:spatialpred}) and
(\ref{eqn:twoDwhite})
behave significantly differently in practice,
and I am not prepared to fully explain the difference,
but it seems to be similar to the gapping of one-dimensional filters.

\par
You might find it alarming
that your teacher is not fully prepared
to explain the difference between a volume and two planes,
but please remember that we are talking about
the factorization of the volumetric spectrum.
Spectral matrices are well known to have structure,
but books on theory typically handle them as simply $\lambda \bold I$.
Anyway, wherever you see an $\bold A$ in a three-dimensional context,
you may wonder whether it should be interpreted as a cubic filter
that takes one volume to another,
or as two planar filters
that take one volume to two volumes
as shown in Figure~\ref{fig:rayab3Doper}.
\sideplot{rayab3Doper}{width=1.50in}{
  An inline 2-D PEF and a crossline 2-D PEF
  both applied throughout the volume.
  To find each filter,
  minimize each output power independently.
}

\subsection{My view of the world}
\par
I start from the idea that the four-dimensional world $(t,x,y,z)$
is filled with expanding spherical waves and with quasispherical waves
that result from reflection from quasiplanar objects
and refraction through quasihomogeneous materials.
We rarely, if ever see
in an observational data cube,
an entire expanding spherical wave,
but we normally have a two- or three-dimensional slice
with some wavefront curvature.
We analyze data subcubes that I call \bx{bricks}.
In any brick we see only local patches of apparent plane waves.
I call them \bx{platelets}.
From the microview of this brick,
the platelets come from the ``great random-point-generator in the sky,''
which then somehow convolves the random points
with a plate-like impulse response.
If we could deconvolve these platelets back to their random source points,
there would be nothing left inside the brick
because the energy would have gone outside.
We would have destroyed the energy inside the brick.
If the platelets were coin shaped,
then the gradient magnitude would convert each coin to its circular rim.
The plate sizes and shapes are all different
and they damp with distance from their centers, as do Gaussian beams.
If we observed {\it rays} instead of wavefront platelets
then we might think of the world as being filled with noodles,
and then.\ .\ .\ .
\par
How is it possible that in a small brick we can do something realistic
about deconvolving a spheroidal impulse response
that is much bigger than the brick?
The same way as in one dimension,
where
in a small time interval we can estimate the correct deconvolution filter
of a long resonant signal.
A three-point filter destroys a sinusoid.
\par
The inverse filter to the expanding spherical wave might be a huge cube.
Good approximations to this inverse at the brick level
might be two small planes.
Their time extent would be chosen to encompass the slowest waves,
and their spatial extent could be two or three points,
representing
the idea that normally we can listen to only one person at a time,
occasionally we can listen to two,
and we can never listen to three people talking at the same time.

\section{WAVE INTERFERENCE AND TRACE SCALING}
\sx{interference}
\sx{scaling a trace}
Although neighboring seismometers tend to show equal powers,
the energy on one seismometer can differ greatly
from that of a neighbor for both theoretical reasons
and practical ones.
Should a trace ever be rescaled
to give it the same energy as its neighbors?
Here we review the strong theoretical arguments against rescaling.
In practice,
however, especially on land where coupling is irregular,
scaling seems a necessity.
The question is,
what can go wrong if we scale traces to have equal energy,
and more basically,
where the proper \bx{scale factor} cannot be recorded,
what should we do to get the best scale factor?
A related question is how to make good measurements of amplitude versus offset.
To understand these issues we review
the fundamentals of wave interference.

\inputdir{scale}

\par
Theoretically, a scale-factor problem arises
because {\it locally}, wavefields, not energies, add.
Nodes on standing waves are familiar from theory,
but they could give you the wrong idea that the concept of node
is one that applies only with sinusoids.
Actually, destructive interference arises 
anytime a polarity-reversed waveform bounces back and crosses itself.
Figure~\ref{fig:super} shows two waves of opposite polarity crossing each other.
\sideplot{super}{width=3in}{
  Superposition of plane waves of opposite polarity.
}
Observe that one seismogram has a zero-valued signal,
while its neighbors have anomalously higher amplitudes
and higher energies than are found far away from the interference.
The situation shown in Figure \ref{fig:super} does not occur easily in nature.
Reflection naturally comes to mind,
but usually the reflected wave
crosses the incident wave at a later time and then they don't extinguish.
Approximate extinguishing occurs rather easily 
when waves are quasi-monochromatic.
We will soon see, however,
that methodologies for finding scales all begin with deconvolution
and that eliminates the monochromatic waves.

\subsection{Computing the proper scale factor for a seismogram}
With data like Figure~\ref{fig:super},
rescaling traces to have equal energy would obviously be wrong.
The question is, ``How can we determine the proper scale factor?''
As we have seen, a superposition of N plane waves exactly
satisfies an N-th order (in $x$) difference equation.
Given a 2-D wave field,
we can find its PEF
by minimizing output power.
Then we ask the question,
could rescaling the traces give a lower output power?
To answer this, we set up an optimization goal:
Given the leveler (be it a cubic PEF or two planar ones),
find the best trace scales.
(After solving this,
we could return to re-estimate the leveler,
and iterate.)
To solve for the scales,
we need a subroutine that scales traces
and the only tricky part is that the adjoint should
bring us back to the space of scale factors.
This is done by \texttt{scaletrace}
\opdex{scaletrace}{trace scaling}{40}{45}{user/gee}
Notice that to estimate scales,
the adjoint forms an inner product of the raw data
on the previously scaled data.
Let the operator implemented by \texttt{scaletrace}
be denoted by $\bold D$,
which is mnemonic for ``data'' and for ``diagonal matrix,''
and let the vector of scale factors be denoted by $\bold s$ and
the leveler by $\bold A$.
Now we consider the fitting goal $\bold 0\approx \bold A \bold D \bold s$.
The trouble with this fitting goal is that the solution
is obviously $\bold s = \bold 0$.
To avoid the trivial solution $\bold s = \bold 0$,
we can choose from a variety of supplemental fitting goals.
One possibility is that for the $i$-th scale factor
we could add the fitting goal $s_i\approx 1$.
Another possibility, perhaps better if some of the signals
have the opposite of the correct polarity,
is that the sum of the scales should be approximately unity.
I regret that time has not yet allowed me
to identify some interesting examples and work them through.

\section{LOCAL MONOPLANE ANNIHILATOR}
\sx{local monoplane annihilator}
\sx{monoplane annihilator}
\sx{annihilator, local monoplane}

%       An interpreter looking at a migrated section containing
%       two dips in the same place knows that something is wrong.
%       To minimize the presence of multiple dipping events in the same place,
%       we can design a rejection filter
%       to remove the best fitting local plane.
%       This is called a LOMOPLAN (LOcal MOno PLane ANnihilator).
%       The output of a LOMOPLAN contains only other dips
%       so minimizing that output should enable us
%       to improve estimation of model parameters and missing data.
%       Although the LOMOPLAN concept applies to models, not data,
%       experience shows that processing field data with a LOMOPLAN
%       quickly identifies data quality goals.

\bx{LOMOPLAN} (LOcal MOno PLane ANnihilator)
is a data-adaptive filter that extinguishes a local monoplane,
but cannot extinguish a superposition of several planes.
We presume an ideal sedimentary model
as made of (possibly curved) parallel layers.
Because of the superposition principle,
data can be a superposition of several plane waves,
but the ideal model should consist locally of only a single plane.
Thus, LOMOPLAN extinguishes an ideal model, but not typical data.
I conceived of LOMOPLAN as the ``ultimate'' optimization criterion
for inversion problems in reflection seismology
\cite[]{Claerbout.sep.73.409}
but it has not yet demonstrated that it can attain that lofty goal.
Instead,
however, working in two dimensions,
it is useful in data interpretation
and in data quality inspection.

\par
The main way we estimate parameters in reflection seismology
is that we maximize the coherence of theoretically redundant measurements.
Thus, to estimate velocity and statics shifts,
we maximize something like the power in the stacked data.
Here I propose another optimization criterion
for estimating model parameters and missing data.
An interpreter looking at a migrated section containing
two dips in the same place
suspects wave superposition more likely than bedding texture superposition.
To minimize the presence of multiple dipping events in the same place,
we should use the mono plane annihilator (\bx{MOPLAN}) filter
as the weighting operator for any fitting goal.
Because the filter is intended for use on images or migrated data,
not on data directly,
I call it a {\it plane} annihilator, not a {\it planewave} annihilator.
(A time-migration or merely a stack, however, might qualify as an image.)
We should avoid using the word ``wavefront''
because waves readily satisfy the superposition principle,
whereas images do not,
and it is this aspect of images that I advocate and formulate
as ``prior information.''

\par
An example of a MOPLAN in two dimensions,
$(\partial_x + p_x \partial_\tau)$,
is explored in Chapter 4 of \bx{PVI},
%\cite{Claerbout.blackwell.92},
where the main goal is to estimate the
$(\tau ,x)$-variation of $p_x$.
Another family of MOPLANs arise from multidimensional
prediction-error filtering
described earlier in this book and
in PVI, Chapter 8.

\par
Here I hypothesize that a MOPLAN may be a valuable weighting function
for many estimation applications in seismology.
Perhaps we can estimate statics, interval velocity, and missing data
if we use the principle of minimizing the power out
of a LOcal MOno PLane ANnihilator (LOMOPLAN) on a migrated section.
Thus, those embarrassing semicircles that we have seen for years
on our migrated sections may hold one of the keys
for unlocking the secrets of statics and lateral velocity variation.
I do not claim that this concept is as powerful as our traditional methods.
I merely claim that we have not yet exploited this concept in a systematic way
and that it might prove useful where traditional methods break.

\par\noindent
\boxit{For an image model of nonoverlapping curved planes,
a suitable choice of weighting function for fitting applications
is the local filter that destroys the best fitting local plane.}

\subsection{Mono-plane deconvolution}
The coefficients of a 2-D monoplane annihilator filter
are defined to be the same as those of a 2-D PEF
of spatial order unity; in other words,
those defined by either (\ref{eqn:spatialpred}) or (\ref{eqn:twoDwhite}).

The filter can be lengthened in time but not in space.
The choice of exactly two columns is a choice
to have an analytic form that can exactly destroy
a single plane, but cannot destroy two.
Applied to two signals that are statistically independent,
the filter (\ref{eqn:twoDwhite})
reduces to the well-known prediction-error filter
in the left column and zeros in the right column.
If the filter coefficients were extended
in both directions on $t$ and to the right on $x$,
the two-dimensional spectrum of the input would be flattened.

\subsection{Monoplanes in local windows}
\inputdir{sep73}
The earth dip changes rapidly with location.
In a small region there is a local dip and dip bandwidth
that determines the best LOMOPLAN (LOcal MOPLAN).
To see how to cope with the edge effects of filtering
in a small region,
and to see how to patch together these small regions,
recall subroutine \texttt{patchn()} \vpageref{/prog:patch} 
and the weighting subroutines that work with it.

\par
Figure~\ref{fig:sigmoid} shows a synthetic model
that illustrates local variation in bedding.
Notice dipping bedding, curved bedding, unconformity between them,
and a fault in the curved bedding.
Also, notice that the image has its amplitude tapered
to zero on the left and right sides.
After local monoplane annihilation (LOMOPLAN),
the continuous bedding is essentially gone.
The fault and unconformity remain.
\plot{sigmoid}{width=6.00in,height=3.5in}{
  Left is a synthetic reflectivity model.
  Right is the result of local monoplane annihilation.
}

\par\noindent
\boxit{The local spatial prediction-error filters contain the essence
of a factored form of the inverse spectrum of the model.}

%\par
%The local spatial prediction-error filters contain the essence
%of a factored form of the inverse spectral matrix of the model.
%A spectral matrix has two aspects:
%a spectral aspect in the prediction-error filter
%and an amplitude aspect as in gain leveling.
%Thus a possible additional step is gaining by the inverse
%square root of the local power.
%Thus the final step in local whitening is to divide the filters
%by the amplitude of the filter output.
%This is like applying automatic \bx{gain} adjustment
%(\bx{AGC}) to the residuals
%in Figure~\FIG{sigmoid0}.
%Doing this gives Figure~\FIG{sigmoid1}.
%\activeplot{sigmoid1}{width=6.00in,height=3.5in}{}{
%       Left is a synthetic reflectivity model.
%       Right is the result of local monoplane annihilation
%       with inverse amplitudes (AGC).
%       }
%
%Notice the model weakens in amplitude along the sides.
%(The designer of this model (me) evidently planned
%to use the model for diffraction and migration.)
%These damping amplitudes are strong on the LOMOPLAN
%because a damping plane wave has angular bandwidth
%greater than zero.
%Two ways to go beyond the monoplane model are (1) to bend the plane,
%or (2) to allow amplitude variation along the plane.
%A one-point filter will
%predict perfectly an exponentially growing or decaying
%amplitude along a plane wave.
%But I prefer a bad prediction of the damping plane
%as an indication that the planar model is breaking down.
%(Here I took a hint from one-dimensional filter analysis.
%Recall Burg's old ``forward and backward'' residual trick
%(\bx{FGDP}, p.~134).
%By forcing a 1-D two-term filter to predict both backward and forward,
%\bx{Burg} avoids perfect predictability on growing exponentials.)
%To achieve imperfect prediction of exponentially growing planes,
%I require one filter
%to extinguish two copies of the data,
%the original copy and a second copy with both $\tau $ and $x$ reversed.
%Note that dips on the reversed copy are the same as on the original
%but amplitude growth on one is decay on the other.
%To give these ideas concrete form,
%I prepared subroutine \LPROG{burgf2} which applies convolution
%with \GPROG{icaf2} to both forward and reversed data.
%\progdex{burgf2}{filter forward and back}
%Monoplane annilhilation can be done with subroutine \GPROG{pef2}.
%Actually, the figures shown here were done
%with a version of {\tt pef2()} that invokes the bidirectional
%filtering in \GPROG{burgf2}.
%I hypothesize that this invocation of symmetry is not worth
%the extra clutter and I plan to repeat the calculations
%with {\tt pef2()} to check.
%%\progdex{moplan}{monoplane annihilate}
%Additionally,
%including the forward and backward residuals
%produces a ``backward'' residual
%that I could not find any reason to display.
%%Also, the display does not explicitly show the patch size.
%%My default values were 20 points on time and 6 channels.
%%The number of patches was designed for a 50\% overlap.
%%The time axes are sampled at 4 ms.
%%I also incorporated a gain leveling ({\tt agc}) option
%%though in principle,
%%gain leveling is a separate process
%%whose natural patch size
%%might differ from that of the MOPLANs.
%%
%%\progdex{lomoplan}{local monoplane filter}
%%Again, \GPROG{lomoplan} seems a substitute for \GPROG{lopef}
%%so I may as well abandon it.
%

Because the plane waves are local,
the illustrations were made with module 
\texttt{lopef} \vpageref{/prog:lopef}.

\subsection{Crossing dips}
\plot{conflict}{width=6.00in,height=2.25in}{
  Conflicting dips before and after
  application of a local monoplane annihilator.
%  Press button for movie.
%  The movie sequence is:
%  1: data,
%  2: data after LOMOPLAN,
%  3: like previous but windows not overlapping,
%  4: predicted data
}
Figure~\ref{fig:conflict} deserves careful study.
The input frame is dipping events with
amplitudes slowly changing as they cross the frame.
The dip of the events is not commensurate with the mesh,
so we use linear interpolation
that accounts for the irregularity along an event.
The output panel tends to be small where there is only a single dip present.
Where two dips cross, they tend to be equal in magnitude.
Studying the output more carefully,
we notice that of the two dips,
the one that is strongest on the input
becomes irregular and noisy on the output,
whereas the other dip tends to remain phase-coherent.
\par
I could rebuild Figure~\ref{fig:conflict} 
to do a better job of suppressing monodip areas
if I passed the image through a lowpass filter,
and then designed a gapped deconvolution operator.
Instead, I preferred to show you high-frequency noise
in the place of an attenuated wavefront.

\par
The residual of prediction-error deconvolution
tends to have a white spectrum in time.
This aspect of deconvolution is somewhat irritating
and in practice it requires us to postfilter for display,
to regain continuity of signals.
As is well known (PVI, for example),
an alternative to postfiltering is to put a gap in the filter.
A gapped filter should work with 2-D filters too,
but it is too early to describe how
experimenters will ultimately choose
to arrange gaps, if any,  in 2-D filters.
There are some interesting possibilities.
(Inserting a gap also reduces the required number of CD iterations.)

\subsection{Tests of 2-D LOMOPLAN on field data}
Although the LOMOPLAN concept was developed for geophysical {\it models},
not raw {\it data},
initial experience showed that the LOMOPLAN program
is effective for quality testing data
and data interpretation.
\par
Some field-data examples are in Figures~\ref{fig:dgulf} and \ref{fig:yc27}.
These results are not surprising.
A dominant local plane is removed,
and noise or the second-from-strongest local plane is left.
These data sets fit the local plane model so well
that subtracting the residual noise from the data made little improvement.
These figures are clearer on a video screen.
To facilitate examination of the residual on Figure~\ref{fig:dgulf} on paper
(which has a lesser dynamic range than video),
I recolored the white residual with a short triangle filter on the time axis.

\plot{dgulf}{width=6.00in,height=3.5in}{
  Data section from the Gulf of Mexico (left)
  and after LOMOPLAN (right)
  Press button for movie.
}

The residual in Figure~\ref{fig:yc27} is large at the dead trace
and wherever the data contains crossing events.
Also, closer examination showed that the strong residual trace
near 1.1 km offset is apparently slightly time-shifted,
almost certainly a cable problem,
perhaps resulting from a combination of the stepout and a few dead pickups.
Overall, the local-plane residual shows a low-frequency water-velocity wave
seeming to originate from the ship.

\plot{yc27}{width=6.00in,height=3.5in}{
  Portion of Yilmaz and Cumro data set 27 (left)
  and after LOMOPLAN (right).
  Press button for movie.
}

%\putbib[MISC]

\section{GRADIENT ALONG THE BEDDING PLANE}
\par
The LOMOPLAN (LOcal MOnoPLane ANnihilator) filter
in three dimensions is a deconvolution filter that takes a volume in
and produces two volumes out.
The $x$-output volume results from a first order
prediction-error filter on the $x$-axis,
and the $y$-output volume is likewise on the $y$-axis.

\par
Although
I conceived of 2-D LOMOPLAN as the ``ultimate'' optimization criterion
for inversion applications in reflection seismology of sedimentary sections,
it turned out that it was more useful in data interpretation
and in data-quality inspection.
In this study, I sought to evaluate usefulness with
{\it three}-dimensional data
such as 3-D stacks or migrated volumes, or 2-D prestack data.

\par
In experimenting with 3-D LOMOPLAN,
I came upon a conceptual oversimplification,
which although it is not precisely correct,
gives a suitable feeling of the meaning of the operator.
Imagine that the earth was flat horizontal layers, except for occasional faults.
Then, to find the faults you might invoke the horizontal
gradient of the 3-D continuum of data.
The horizontal components of gradient vanish except at a fault,
where their relative magnitudes tell you the orientation of the fault.
Instead of using the gradient vector,
you could use prediction-error filters of first order (two components)
along $x$ and $y$ directions.
3-D LOMOPLAN is like this,
but the flat horizontal \bx{bedding} may be dipping or curved.
No output is produced (ideally) except at faults.
The 3-D LOMOPLAN is like the gradient
{\it along the plane of the bedding}.
It is nonzero where the bedding has an intrinsic change.

\par\noindent
\boxit{LOMOPLAN flags the bedding where there is an intrinsic change.}

\subsection{Definition of LOMOPLAN in 3-D}
Three-dimensional LOMOPLAN is somewhat like multiple passes
of two-dimensional LOMOPLAN;
i.e., we first LOMOPLAN the $(t,x)$-plane for each $y$,
and then we
LOMOPLAN the $(t,y)$-plane for each $x$.
Actually, 3-D LOMOPLAN is
a little more complicated than this.
Each LOMOPLAN filter is designed on all the data in a small $(t,x,y)$ volume.
\par
%I began from my earlier two-dimensional code
%and made the obvious extensions to three dimensions.
%For example,
%converting subroutine \texttt{icaf2()} \vpageref{/prog:icaf2} to the 3-D version
%{\tt icaf3()} gives a subroutine that convolves
%a volume over a volume to get a volume.
%When we need a 2-D filter,
%we pick {\tt a3=1} and with it,
%subroutine {\tt icaf3()}
%convolves the planar filter throughout the input volume
%and thus gives an output volume.
%When we want a monoplane filter orthogonally oriented,
%we take {\tt a2=1} but {\tt a3=2}.

\par
To put the LOcal in LOMOPLAN we use subcubes (bricks).
Recall that we can do 2-D LOMOPLAN with
the prediction-error subroutine 
\texttt{find\_lopef()} \vpageref{/prog:lopef}.
To do 3-D LOMOPLAN we need to make two calls to subroutine
{\tt find\_lopef()},
one for the $x$-axis in-line planar filters
and one for the $y$-axis crossline filters.
That is what I will try next time
I install this book on a computer with a bigger memory.

\subsection{The quarterdome  3-D synthetic (qdome)}
\sx{quarterdome 3-D synthetic (qdome)}
\sx{qdome}
\inputdir{sep77}
Figure~\ref{fig:sigmoid}
used a model called ``\bx{Sigmoid}.''
Using the same modeling concepts,
I set out to make a three-dimensional model.
The model has horizontal layers near the top,
a Gaussian appearance in the middle, and dipping layers on the bottom,
with horizontal unconformities between the three regions.
Figure~\ref{fig:qdomesico} shows
a vertical slice through the 3-D ``qdome'' model
and components of its LOMOPLAN.
There is also a fault that will be described later.
\plot{qdomesico}{width=6.00in,height=3.5in}{
  Left is a vertical slice through the 3-D ``qdome'' model.
  Center is the in-line component of the LOMOPLAN.
  Right is the cross-line component of the LOMOPLAN.
}
The most interesting part of the qdome model is the Gaussian center.
I started from the equation of a \bx{Gaussian}
\begin{equation}
z(x,y,t) \quad = \quad e^{-(x^2+y^2)/ t^2}
\end{equation}
and backsolved for $t$
\begin{equation}
t(x,y,z) \quad = \quad \sqrt{\frac{x^2+y^2 }{ -\ln z}}
\end{equation}
Then I used a random-number generator
to make a blocky one-dimensional impedance function of $t$.
At each $(x,y,z)$ location in the model
I used the impedance at time $t(x,y,z)$,
and finally defined reflectivity as the logarithmic derivative
of the impedance.
Without careful interpolation (particularly where the beds pinch out)
a variety of curious artifacts appear.
I hope to find time to
use the experience of making the qdome model
to make a tutorial lesson on interpolation.
A refinement to the model is that within a certain subvolume
the time $t(x,y,z)$ is given a small additive constant.
This gives a fault along the edge of the subvolume.
Ray \bx{Abma} defined the subvolume for me in the qdome model.
The fault looks quite realistic,
and it is easy to make faults of any shape,
though I wonder how they would relate to realistic fault dynamics.
Figure~\ref{fig:qdometoco} shows
        a top view of
        the 3-D qdome model
        and components of its LOMOPLAN.
\noindent
Notice that the cross-line spacing
has been chosen to be double the in-line spacing.
Evidently a consequence of this,
in both
Figure~\ref{fig:qdomesico} and
Figure~\ref{fig:qdometoco}, is that the Gaussian dome is not so well suppressed
on the crossline cut as on the in-line cut.
By comparison, notice that the horizontal bedding above the dome
is perfectly suppressed,
whereas the dipping bedding below the dome is imperfectly suppressed.
\plot{qdometoco}{width=6.00in,height=2.1in}{
  Left is a horizontal slice through the 3-D qdome model.
  Center is the in-line component of the LOMOPLAN.
  Right is the cross-line component of the LOMOPLAN.
%  Press button for volume view.
}

\par
Finally, I became irritated at the need to look at {\it two} output volumes.
Because I rarely if ever interpreted the polarity of the LOMOPLAN components,
I formed their sum of squares and show the single
square root volume in Figure~\ref{fig:qdometora}.

\plot{qdometora}{width=6.00in,height=3.2in}{
  Left is the model.
  Right is the magnitude of the LOMOPLAN
  components in Figure \protect\ref{fig:qdometoco}.
%  Press button for volume view.
}

\section{3-D SPECTRAL FACTORIZATION}
Hi Sergey, Matt, and Sean,
Here are my latest speculations, plans:

The 3-D Lomoplan resembles a gradient, one field in, two or three out.
Lomoplan times its adjoint is like a generalized laplacian.
Factorizing it yields a lomoplan generalization of the helix derivative,
i.e. a one-to-one operator with the same spectral charactoristic
as the original lomoplan.
It will probably not come out to be a juxtaposition of planes,
will be more cube like.

The advantage of being one-to-one is
that it can be used as a preconditioner.
The application, naturally enough,
is estimating things with a prescribed dip spectrum.
Things like missing data and velocities.

Why use multiplanar lomoplan estimates if they will then be
converted by this complicated process into a cube?
Why not estimate the cube directly?  Maybe to impose
the ``pancake'' model instead of the noodle model of covariance.
Maybe to reduce the number of coefficients to estimate.

I haven't figured out yet how to convert this speculation
into an example leading to some figures.
If you like the idea, feel free to beat me to it :)


%\subsection{Attempted field test of 3-D LOMOPLAN}
%I experimented with some 3-D data to see if the LOMOPLAN
%view would prove interesting.
%Preliminary views were not,
%so I omit them here.
%First I looked at the Gulf of Thailand GSI migrations.
%Unfortunately all I could find was the pixel byte form,
%so I converted that back to floats.
%Second, I examined Mihai's unmigrated stack from
%Halliburton's High Island 3D spec survey.
%I experimented first with the shallow faults,
%but these were confounded by multiples
%and the little dip present made the LOMOPLAN time slices in no way
%more interesting than those of the input data.
%A problem I had with the early times on this survey
%is that the crosslines had noticeable
%(but inexplicable) timeshifts from one line to another.
%Thus the crosslines, and hence the 3-D nature of the LOMOPLAN
%was not exemplified.
%The crossline problem was absent at later times.
%Because the computations were fairly demanding however,
%before results could be obtained
%I turned to learning the parallel computer,
%and got caught up with the good results
%I obtained elsewhere in this monograph with steep-dip deconvolution.
%\par
%Prestack two-dimensional data offers another interesting area
%for investigation.

\bibliographystyle{seg}\bibliography{SEP2,jfc}

%\end{notforlecture}

\clearpage

