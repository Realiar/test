% copyright (c) 1998 Jon Claerbout

\title{Spatial aliasing and scale invariance}
\author{Jon Claerbout}
\maketitle
\label{paper:lal}

\sx{alias}
\sx{spatial aliasing}
\sx{scale invariance}

\par
Landforms are not especially predictable.
Therefore, crude PEF approximations are often satisfactory.
Wavefields are another matter.
Consider the ``shape'' of the acoustic wavefronts
at this moment in the room you are in.
The acoustic wavefield has statistical order in many senses.
If the 3-D volume is filled with waves emitted from a few point sources,
then (with some simplifications)
what could be a volume of information is actually a few 1-D signals.
When we work with wavefronts we can hope for more dramatic,
even astounding, results from estimating properly.

%\par
%In its simplest form,
%the \bx{Nyquist} condition says that
%we can have no frequencies higher than two points per wavelength.
%In migration, this is a strong constraint on data collection.
%It seems there is no escape.
%Yet, in applications dealing with a CMP gather
%% (such as in Figure~\ref{lal/conj-stretch} or \ref{lal/conj-stack}),
%we see data with spatial frequencies that exceed Nyquist
%and we are not bothered, because after \bx{NMO},
%these frequencies are OK.
%Nevertheless, such data is troubling because
%it breaks many of our conventional programs,
%such as downward continuation with finite differences
%or with Fourier transforms.
%(No one uses focusing for \bx{stacking}.)
%Since NMO overcomes
%the limitation imposed
%by the simple statement of the Nyquist condition,
%we revise the condition to say that
%the real limitation is on the spectral bandwidth,
%not on the maximum frequency.
%Mr.~Nyquist does not tell us where that bandwidth must be located.
%Further, it seems that precious bandwidth {\it need not be contiguous.}
%The signal's spectral band can be split into pieces
%and those pieces positioned in different places.
%Fundamentally, the issue is whether the total bandwidth exceeds Nyquist.
%%Noncontiguous Nyquist bands are depicted in Figure~\FIG{nytutor}.%
%%\ACTIVESIDEPLOT{nytutor}{width=3in}{nytutor}{
%%      Hypothetical spatial frequency bands.
%%      Top is typical.
%%      Middle for data skewed with $\tau=t-px$.
%%      Bottom depicts data with wave arrivals
%%      from three directions.
%%      }
%%
%%\par
%Noncontiguous bandwidth arises naturally with
%two-dimensional data where there are several plane-waves present.
%There the familiar spatial Nyquist limitation 
%oversimplifies real life because the plane-waves link time and space.
\par\noindent
\boxit{ 
        The plane-wave model links an axis that is not aliased (time)
        with axes (space) that often are.
        }
\par
%%\subsection{Aliasing a plane-wave chirp}
%Spatial aliasing is often described as being
%like temporal aliasing but on another axis.
%Mathematically,
%aliasing on the two axes is independent,
%however, the plane-wave model links them
%in our day-to-day experience.
%The plane wave model links an axis (time) that is not aliased
%with axes (space) that might be.
%\par
%A function generally useful with seismic vibrator sources
%is the ``gated-\bx{chirp} function''.
%Within a specified time gate
%this function is a sinusoid with a time-variable frequency.
%Here we will take this signal to be defined by
%\begin{equation}
%f(\tau ) \quad = \quad
%       \left\{
%               \begin{array}{ll}
%                       \sin( \omega_{\max} \tau^2 / 2\tau_{\max} )
%                               & \quad 0 \le \tau \le \tau_{\max}  \\
%                       0       & \quad \mbox{otherwise}
%               \end{array}
%       \right.
%\end{equation}
%The phase $\phi$ and instantaneous frequency $\omega$
%of this chirp signal is
%\begin{eqnarray}
%\phi   &=& 0.5\ \omega_{\max} \ \tau^2 / \tau_{\max}   \\
%\omega &=& {d\phi \over d\tau} \quad = \quad \omega_{\max} \ \tau / \tau_{\max}
%\end{eqnarray}
%which shows that as
%$\tau$ ranges from $0$ to $\tau_{\max}$,
%the frequency $\omega$ ranges from $0$ to $\omega_{\max}$.
%\par
%Now consider the chirp signal seen on a wave, say $f(t-px)$.
%For constant $x$ we see a chirp signal,
%possibly shifted on the time axis.
%For constant $t$ we see a chirp function
%along the $x$ axis,
%but the $-p$ causes the chirp to
%be reversed and stretched.
%Figure~\FIG{alias2d} shows
%the chirp wave function $f(t-px)$ for $p=0.45$
%and for $\omega_{\max}=2\pi$.
%\activeplot{alias2d}{width=6in,height=3in}{}{
%       A coarsely sampled chirp function on a wavefront.
%       View figure at a grazing angle from various directions.
%       }
%Since $\omega_{\max}=2\pi$ is double the Nyquist frequency,
%you see aliasing on the time axis in Figure~\FIG{alias2d}.
%In other words, along the left edge, the frequency first
%increases with time until it reaches the Nyquist frequency and then,
%as frequency goes beyond Nyquist,
%the apparent frequency decreases.
%Something else happens on the space axis
%which is best seen along the bottom edge of the plot.
%There the frequency sweeps steadily from zero to Nyquist.
%\par
%Thus, we see that the continuum is different from the sampled world.
%In a continuum, the function $f(t-px)$
%at constant $t$ looks like the same function at constant $x$
%except for shifting, reversal, and stretching.
%In the sampled world we see different functions on each axis.
%The sampled world matches the continuum only at low frequencies.
%\par
%Real life would be more like Figure~\FIG{alias2d}
%if we would interchange the time and space axis
%because it is easy to sample densely enough in time,
%or to high-cut filter the data before sampling it
%but it is hard to get enough observing locations in space.
%The result of insufficient density of stations
%is that seismic data is often aliased in space.
%Spatial aliasing is when a spatial frequency
%looks lower than it would
%if the data were more densely sampled in space.
%%\section{ORTHOGONALITY OF CROSSING PLANE WAVES}
%%\par
%%As an alternative to the customary approach
%%of defining and analyzing aliasing by Fourier analysis,
%%I suggest that spatial aliasing may be defined and analyzed
%%with reference to plane waves.
%%Consider two sinusoidal signals of different frequencies.
%%Since they have different frequencies
%%they should be orthogonal,
%%but they need not be orthogonal if there is aliasing,
%%because aliasing can make a high frequency look like a low one.
%%Now let us see if we can substitute
%%the word ``dip''
%%for the word ``frequency.''
%%Can we say that plane waves with different dips should be orthogonal?
%%
%%\par
%%Normally, waves do not contain zero frequency.
%%Thus the time integral of a waveform normally vanishes.
%%Likewise,
%%for a dipping plane wave, the time integral vanishes.
%%Likewise,
%%a line integral
%%across the $(t,x)$-plane
%%along a straight line that crosses a plane wave
%%or a dipping plane wave vanishes.
%%Likewise,
%%two plane waves with different slopes should be orthogonal
%%if one of them has zero mean.
%%The other wave, however, need not have zero mean.
%%This ``other wave'' need not be a wave at all,
%%but could be an impulse function,
%%say $\delta(t-px)$,
%%spread over a mesh.
%%Once it is spread out, it will look like an impulsive plane wave.
%%The purpose of this impulsive plane wave is to multiply onto data,
%%thereby enabling us to do a line integral of the data.
%%What is important is how we represent this impulse function on the mesh.
%%Theoretically, we have line integrals that should vanish
%%when they cross a zero-mean plane wave.
%%When in practice they do not,
%%it means that we have not done
%%a good job of representing the line integral.
%%
%%
%%\par
%%Fourier analysis and sinc functions
%%play an important role in integrals along straight lines.
%%Production reflection seismic data processing
%%involves much effort with line integrals
%%along hyperbolic curves and other shapes---rarely straight lines.
%%Hopefully, the theoretical concepts above will be suggestive
%%of further theoretical and practical developments.
%%
%%%\subsection{Rambling thoughts}
%%%\par
%%%Next I assume considerable facility with Fourier analysis.
%%%Now imagine the function for Figure \FIG{alias2d} had been 
%%%a sinc function with its width parameter adjusted so
%%%to match aliasing on the coarse axis (axis 1).
%%%The FT of a line is another line.
%%%I have a sinc convolved with a line.
%%%So in $(\omega, k)$-space it seems like a line
%%%convolved (multiplied?) with a rectangle.
%%
%%%%%%%%
%\subsection{Relation of missing data to inversion}
%We take {\it data space} to be a uniform mesh
%on which some values are given and some are missing.
%We rarely have missing values on a time axis,
%but commonly have missing values on a space axis,
%i.e.,~missing signals.
%Missing signals (traces) happen occasionally for miscellaneous reasons,
%and they happen systematically because of \bx{alias}ing and \bx{truncation}.
%The aliasing arises for economic reasons---saving instrumentation
%by running receivers far apart.
%Truncation arises at the ends of any survey,
%which, like any human activity, must be finite.
%Beyond the survey lies more hypothetical data.
%The traces we will find for the \bx{missing data}
%are not as good as real observations,
%but they are closer to reality
%than supposing unmeasured data is zero valued.
%Making an image with a single application of an adjoint modeling operator
%amounts to assuming that data vanishes beyond its given locations.
%\bxbx{Migration}{migration}
%is an example of an economically important process
%that makes this assumption.
%Dealing with missing data is a step beyond this.
%In \bx{inversion}, restoring \bx{missing data}
%reduces the need for arbitrary model filtering.
%\subsection{The world is filled with local plane waves.}
%\sx{plane waves}
%In your ears now are sounds from various directions.
%From moment to moment the directions change.
%Momentarily, a single direction (or two) dominates.
%Your ears sample only two points in x-space.
%Earthquake data is a little better.
%Exploration data is much better and
%sometimes seems to satisfy the Nyquist requirement,
%especially when we forget that the world is 3-D.

\par
We often characterize data from
any region of $(t,x)$-space as ``good'' or ``noisy''
when we really mean it contains ``few'' or ``many'' plane-wave events
in that region.
Where regions are noisy,
there is no escaping the simple form of the Nyquist limitation.
Where regions are good we may escape it.
Real data typically contains both kinds of regions.
Undersampled data with a broad distribution of plane waves is nearly hopeless.
Undersampled data with a sparse distribution of plane waves
offer us the opportunity to resample without aliasing.
Consider data containing a spherical wave.
The angular bandwidth in a plane-wave decomposition appears huge
{\it until we restrict attention to a small region} of the data.
(Actually a spherical wave contains very little information
compared to an arbitrary wave field.)
It can be very helpful in reducing the local angular bandwidth
if we can deal effectively with tiny pieces of data.
%as we did in chapter \UNI .
If we can deal with tiny pieces of data,
then we can adapt to rapid spatial and temporal variations.
This chapter shows such tiny windows of data.

\section{INTERPOLATION BEYOND ALIASING}
%I have long marveled at the ability of humans to interpolate
%seismic data containing mixtures of dips where spatial frequencies
%exceed the Nyquist limits.
%These limits are hard limits on migration programs.
%Costly field-data-acquisition activities
%are designed with these limits in mind.
%I feared this human skill of going beyond the limit was deeply nonlinear
%and beyond reliable programming.
%Now, however, I have obtained results
%comparable in quality to those of S.~\bx{Spitz},
%and I am doing so in a way that seems reliable---using two-stage,
%linear least squares.
%\par
%Here we attack the problem of missing data arising in a regular pattern
%such as alternate traces being missing.
%This defeats earlier methods
%because every output requires missing data as inputs.
%\subsection{Traditional 2-D interpolation before aliasing}

A traditional method of data interpolation on a regular mesh
is a four-step procedure:
(1) Set zero values at the points to be interpolated;
(2) \bx{Fourier transform};
(3) Set to zero the high frequencies;
and
(4) Inverse transform.
This is a fine method and is suitable for many applications
in both one dimension and higher dimensions.
However,
this method fails to take advantage of our prior knowledge
that seismic data has abundant fragments of plane waves
that link an axis that is not aliased (time)
to axes that often are (space).
%Where the method falls down is where more is needed than simple
%interlacing---for example,
%when signal values are required beyond the ends of
%the data sample.
%The simple Fourier method of interlacing also loses its applicability
%when known data is irregularly distributed.
%An example of an application in two dimensions of the methodology
%of this section is given in the section on tomography
%beginning on page~\pageref{lal/tomography'}.

\subsection{Interlacing a filter}
\sx{interlacing a filter}
\sx{filter ! interlaced}
The filter below can
be designed despite alternate missing traces.
This filter destroys plane waves.
If the plane wave should happen to pass halfway between
the ``d'' and the ``e'',
those two points could interpolate the halfway point,
at least for well-sampled temporal frequencies,
and the time axis should always be well sampled.
For example, $d=e=-.5$ would almost destroy the plane wave
and it is an aliased planewave for its higher frequencies.
\begin{equation}
   \begin{array}{ccccccccc}
      a     &\cdot &b     &\cdot &c     &\cdot &d     &\cdot &e     \\
      \cdot &\cdot &\cdot &\cdot &\cdot &\cdot &\cdot &\cdot &\cdot \\
      \cdot &\cdot &\cdot &\cdot &1     &\cdot &\cdot &\cdot &\cdot \end{array}
\label{eqn:ilacefil}
\end{equation}
We could
use module \texttt{pef} \vpageref{lst:pef}
to find the filter (\ref{eqn:ilacefil}),
if we set up the 
%constraint array {\tt afre($\ast$,$\ast$)} 
lag table \texttt{lag}
appropriately.
Then we could throw away alternate zeroed rows and columns (rescale the lag) to get the filter
\begin{equation}
   \begin{array}{ccccc}
      a     &b     &c     &d     &e     \\
      \cdot &\cdot &1     &\cdot &\cdot \end{array}
\label{eqn:noilace}
\end{equation}
which could be used with subroutine \texttt{mis1()} \vpageref{lst:mis1},
to find the interleaved data
because both
the filters (\ref{eqn:ilacefil}) and (\ref{eqn:noilace})
have the same dip characteristics.

\inputdir{lace}

\par
Figure~\ref{fig:lace3} shows three plane waves recorded on five channels
and the interpolated data.
\plot{lace3}{width=6in}{
  Left is five signals, each showing three arrivals.
  With the data shown on the left
  (and no more),
  the signals have been interpolated.
  Three new traces appear between each given trace,
  as shown on the right.
}
Both the original data and the interpolated data can be described
as ``beyond \bx{alias}ing,'' because on the input data
the signal shifts exceed the signal duration.
The calculation requires only a few seconds
of a two-stage least-squares method, in which the first stage
estimates a PEF (inverse spectrum) of the known data,
and the second uses the PEF to estimate the missing traces.
Figure~\ref{fig:lace3} comes from PVI
which introduces the clever method described above.
We will review how that was done and examine the F90 codes
that generalize it to $N$-dimensions.
Then we'll go on to more general methods
that allow missing data in any location.
Before the methods of this section
are applied to field data for migration,
data must be broken into many overlapping tiles
of size about like those shown here
and the results from each tile pieced together.
That is described later in chapter \ref{paper:pch}.
\par
A PEF is like a differential equation.
The more plane-wave solutions you expect,
the more lags you need on the data.
Returning to Figure~\ref{fig:lace3},
the filter must cover four traces (or more)
to enable it to predict three plane waves.
In this case,
\texttt{na=(9,4)}.
As usual, the spike on the 2-D PEF is at
\texttt{center=(5,1)}.
We see the filter is expanded by a factor of
\texttt{jump=4}.
The data size is
\texttt{nd=(75,5)}
and \texttt{gap=0}.
Before looking at the code
\texttt{lace} \vpageref{lst:lace}
for estimating the PEF,
it might be helpful to recall the basic utilities
\texttt{line2cart} and
\texttt{cart2line}
\vpageref{lst:cartesian}
for conversion between a multidimensional space and
the helix filter lag.
We need to sweep across the whole filter
and ``stretch'' its lags on the 1-axis.
We do not need to stretch its lags on the 2-axis
because the data has not yet been interlaced by zero traces.
\moddex{lace}{fill missing traces by rescaling PEF}{27}{65}{user/gee}
The line \texttt{ii[0] *= jump}
means we interlace the 1-axis but not the 2-axis because
the data has not yet been interlaced with zero traces.
\begin{comment}
For a 3-D filter
\texttt{aa(na1,na2,na3)},
the somewhat obtuse expression
\texttt{(/na(1)*jump, na(2:)/)}
is a three component
vector containing
\texttt{(na1*jump, na2, na3)}.
\end{comment}
\par
After the PEF has been found, we can get missing data in
the usual way with with module
\texttt{mis2} \vpageref{lst:mis2}.


\section{MULTISCALE, SELF-SIMILAR FITTING}
\sx{multiscale fitting}
\sx{self-similar fitting}
\sx{goal ! multiscale self-similar}

Large objects often resemble small objects.
To express this idea we use {\it \bx{axis scaling}}
and we apply it to the basic theory
of prediction-error filter (PEF) fitting
and missing-data estimation.
\par
Equations (\ref{eqn:mspef}) and (\ref{eqn:msmis}) compute the same thing
by two different methods,
$ \bold r = \bold Y \bold a$ and
$ \bold r = \bold A \bold y$.
When it is viewed as fitting goals minimizing $||\bold r||$
and used along with suitable constraints,
(\ref{eqn:mspef}) leads to finding filters and \bx{spectra},
while
(\ref{eqn:msmis}) leads to finding \bx{missing data}.

\begin{equation}
\left[ 
\begin{array}{c}
  r_1 \\ 
  r_2 \\ 
  r_3 \\ 
  r_4 \\ 
  r_5 \\ 
  \hline
  r_6 \\
  r_7 \\
  r_8 \\
  r_9
  \end{array} \right] 
\eq
\left[ 
\begin{array}{ccc}
  y_2 & y_1 \\
  y_3 & y_2 \\
  y_4 & y_3 \\
  y_5 & y_4 \\
  y_6 & y_5 \\
  \hline
  y_3 & y_1 \\
  y_4 & y_2 \\
  y_5 & y_3 \\
  y_6 & y_4 
  \end{array} \right] 
\; \left[ 
\begin{array}{c}
  a_1 \\ 
  a_2 \end{array} \right]
\quad\quad\quad {\rm or}\quad\quad
\left[ 
\begin{array}{c}
  \bold r_1 \\ 
  \bold r_2
  \end{array} \right] 
\ =\ 
\left[ 
\begin{array}{c}
  \bold Y_1 \\
  \bold Y_2
  \end{array} \right] 
\;
\bold a
\label{eqn:mspef}
\end{equation}

\begin{equation}
\left[ 
\begin{array}{c}
  r_1 \\ 
  r_2 \\ 
  r_3 \\ 
  r_4 \\ 
  r_5 \\ 
  \hline
  r_6 \\ 
  r_7 \\ 
  r_8 \\ 
  r_9 
  \end{array} \right] 
\eq
\left[ 
\begin{array}{cccccc}
  a_2   & a_1   & \cdot & \cdot & \cdot  & \cdot \\
  \cdot & a_2   & a_1   & \cdot & \cdot  & \cdot \\
  \cdot & \cdot & a_2   & a_1   & \cdot  & \cdot \\
  \cdot & \cdot & \cdot & a_2   & a_1    & \cdot \\
  \cdot & \cdot & \cdot & \cdot & a_2    & a_1   \\
  \hline
  a_2   & \cdot & a_1   & \cdot & \cdot  & \cdot \\
  \cdot & a_2   & \cdot & a_1   & \cdot  & \cdot \\
  \cdot & \cdot & a_2   & \cdot & a_1    & \cdot \\
  \cdot & \cdot & \cdot & a_2   & \cdot  & a_1   
  \end{array} \right] 
\; \left[ 
\begin{array}{c}
  y_1 \\ 
  y_2 \\ 
  y_3 \\ 
  y_4 \\ 
  y_5 \\ 
  y_6
  \end{array} \right]
\quad\quad {\rm or}\quad\quad
\left[ 
\begin{array}{c}
  \bold r_1 \\ 
  \bold r_2 
  \end{array} \right] 
\ =\ 
\left[ 
\begin{array}{c}
  \bold A_1 \\
  \bold A_2
\end{array}
\right]
\;
\bold y
\label{eqn:msmis}
\end{equation}

\par
A new concept embedded in (\ref{eqn:mspef}) and (\ref{eqn:msmis})
is that one filter can be applicable for different \bx{stretching}s
of the filter's time axis.
One wonders,
``Of all classes of filters,
what subset remains appropriate for stretchings of the axes?''

\subsection{Examples of scale-invariant filtering}
When we consider all functions with vanishing gradient,
we notice that the gradient vanishes whether it is represented as
$(1,-1)/\Delta x$ or as
$(1,0,-1)/2\Delta x$.
Likewise for the Laplacian, in one dimension or more.
Likewise for the wave equation, as long as there is no viscosity
and as long as the time axis and space axes are stretched
by the same amount.
The notion of ``dip filter'' seems to have no formal definition,
but the idea that the spectrum should depend mainly on slope
in Fourier space implies a filter that is scale-invariant.
I expect
the most fruitful applications
to be with \bx{dip filter}s.
\sx{filter ! dip}

\par
Resonance or \bx{viscosity} or damping easily spoils scale-invariance.
The resonant frequency of a filter shifts if we stretch the time axis.
The difference equations
\begin{eqnarray}
y_t - \alpha   y_{t-1} &=& 0  \label{eqn:sparsedecay1} \\
y_t - \alpha^2 y_{t-2} &=& 0  \label{eqn:sparsedecay}
\end{eqnarray}
both have the same solution $y_t = y_0 \alpha^{-t}$.
One difference equation has the filter
$(1,-\alpha)$,
while the other has the filter
$(1,0,-\alpha^2)$,
and $\alpha$ is not equal to $\alpha^2$.
Although these operators differ,
when $\alpha \approx 1$ they might provide the same general utility,
say as a roughening operator in a fitting goal.

\par
Another aspect to scale-invariance work is the presence
of ``parasitic'' solutions,
which exist but are not desired.
For example, another solution to $y_t -  y_{t-2}=0$
is the one that oscillates at the Nyquist frequency.

\par
(Viscosity does not necessarily introduce an inherent length
and thereby spoil scale-invariance.
The approximate frequency independence of sound absorption per wavelength
typical in real rocks is a consequence
of physical inhomogeneity at all scales.
See for example \bx{Kjartansson}'s \bx{constant Q} viscosity,
\sx{Q}
described in \bx{IEI}.
Kjartansson teaches that
the decaying solutions $t^{-\gamma}$ are scale-invariant.
There is no ``decay time'' for the function $t^{-\gamma}$.
Differential equations of finite order and
difference equations of finite order cannot produce
$t^{-\gamma}$ damping,
yet we know that such damping is important in observations.
It is easy to manufacture
$t^{-\gamma}$ damping
in Fourier space;
$\exp[(-i\omega)^{\gamma+1}]$ is used.
Presumably,
difference equations can make reasonable approximations
over a reasonable frequency range.)

\subsection{Scale-invariance introduces more fitting equations}
\inputdir{multiscale}
The fitting goals (\ref{eqn:mspef}) and (\ref{eqn:msmis}) have
about double the usual number of fitting equations.
Scale-invariance {\it introduces extra equations}.
If the range of scale-invariance is wide, there will be more equations.
Now we begin to see the big picture.
\begin{enumerate}
\item Refining a model mesh improves accuracy.
\item Refining a model mesh makes empty bins.
\item Empty bins spoil analysis.
\item If there are not too many empty bins we can find a PEF.
\item With a PEF we can fill the empty bins.
\item To get the PEF and to fill bins we need enough equations.
\item Scale-invariance introduces more equations.
\end{enumerate}
An example of these concepts is shown in Figure \ref{fig:mshole}.
\plot{mshole}{width=6.0in,height=3in}{
  Overcoming aliasing with multiscale fitting.
}

Additionally, when we have a PEF,
often we still cannot find missing data
because conjugate-direction iterations do not converge fast enough
(to fill large holes).
Multiscale convolutions should converge quicker
because they are like mesh-refinement, which is quick.
An example of these concepts is shown in Figure \ref{fig:msiter}.
\sideplot{msiter}{width=3.0in,height=3.9in}{
  Large holes are filled faster with
  multiscale operators.
}

%\begin{notforlecture}
\subsection{Coding the multiscale filter operator}
%Many applications could need slightly different equations, namely
%\begin{equation}
%\left[ 
%\begin{array}{c}
%  \bold 0 \\ 
%  \bold 0
%  \end{array} \right] 
%\quad = \quad
%\left[ 
%\begin{array}{cc}
%  w_1\bold I &    \bold 0\\ 
%     \bold 0 & w_2\bold I
%  \end{array} \right] 
%\
%\left[ 
%\begin{array}{c}
%  \bold Y_1 \\
%  \bold Y_2
%  \end{array} \right] 
%\;
%\bold a
%\ +\ 
%\left[ 
%\begin{array}{c}
%  \bold r_1 \\ 
%  \bold r_2
%  \end{array} \right] 
%\label{eqn:wtpef}
%\end{equation}
%and
%\begin{equation}
%\left[ 
%\begin{array}{c}
%  \bold 0 \\ 
%  \bold 0
%  \end{array} \right] 
%\quad = \quad
%\left[ 
%\begin{array}{cc}
%  w_1\bold I &    \bold 0\\ 
%     \bold 0 & w_2\bold I\\ 
%  \end{array} \right] 
%\
%\left[ 
%\begin{array}{c}
%  \bold A_1 \\
%  \bold A_2
%  \end{array} \right] 
%\;
%\bold y
%\ +\ 
%\left[ 
%\begin{array}{c}
%  \bold r_1 \\ 
%  \bold r_2
%  \end{array} \right] 
%\label{eqn:wtmis}
%\end{equation}
%where $w_1$ and $w_2$ are weighting scale factors.
%This added complication can be easily overcome when putting
%the scaling factor is put in the central loops in the program (which I did).
%It would be more efficient, however, to take the scale factor
%out of the inner loop and apply it to the residual directly.
%I didn't do this because it would clutter the program
%and an optimizing compiler
%might take care of it anyway.
\par
Equation~(\ref{eqn:mspef}) shows an example
where the first output signal is the ordinary one
and the second output signal used a filter interlaced with zeros.
We prepare subroutines that allow for more output signals,
each with its own filter interlace parameter
given in the table {\tt jump[ns]}.
Each entry in the jump table corresponds to
a particular scaling of a filter axis.
The number of output signals is {\tt ns} and the
number of zeros interlaced between filter points 
for the {\tt j}-th signal is {\tt jump[j]-1}.
%Also, there is the weighting scale factor for each scaling,
%{\tt wt(ns)}.
%\progdex{msicaf1}{multiscale conv 1-D}
\par
The multiscale helix filter is defined in module
\texttt{mshelix} \vpageref{lst:mshelix}, analogous to the
single-scale module \texttt{helix} \vpageref{lst:helix}.
A new function
\texttt{onescale}
extracts our usual helix filter
of one particular scale
from the multiscale filter.

\moddex{mshelix}{multiscale helix filter definition}{25}{43}{user/gee}

We create a multscale helix with module
\texttt{createmshelix} \vpageref{lst:createmshelix}.
An expanded scale helix filter is like an ordinary helix filter
except that the lags are scaled according to a \texttt{jump}.

\moddex{createmshelix}{create multiscale helix}{41}{81}{user/gee}

\par
First we examine code for estimating a prediction-error filter
that is applicable at many scales.
We simply invoke the usual filter operator
\texttt{hconest} \vpageref{lst:hconest}
for each scale.

\opdex{mshconest}{multiscale convolution, adjoint is the filter}{48}{51}{user/gee}


\sx{filter ! multiscale prediction-error}

\par
The \bx{multiscale prediction-error filter} finding subroutine
is nearly identical to the usual subroutine
\texttt{find\_pef()} \vpageref{lst:pef}.
(That routine cleverly ignores missing data while estimating a PEF.)
To easily extend {\tt pef} to multiscale filters
we replace its call to the ordinary helix
filter module
\texttt{hconest} \vpageref{lst:hconest}
by a call to \texttt{mshconest}.
\moddex{mspef}{multiscale PEF}{26}{49}{user/gee}
The purpose of \texttt{pack(dd,.true.)}
is to produce the one-dimensional array expected by
our solver routines.


\par
%Likewise, I coded up
Similar code applies to
the operator in
(\ref{eqn:msmis})
which is needed for missing data applications.
This is like
\texttt{mshconest} \vpageref{lst:mshconest}
except the adjoint is not the filter but the input.

\opdex{mshelicon}{multiscale convolution, adjoint is the input}{26}{30}{user/gee}
The multiscale missing-data module \texttt{msmis2}
is just like the usual missing-data module 
\texttt{mis2} \vpageref{lst:mis2}
except that
the filtering is done with the multiscale filter
\texttt{mshelicon}. % \vpageref{lst:mshelicon}.

\moddex{msmis2}{multiscale missing data}{29}{53}{user/gee}

%\putbib[MISC]

%\section{ONE WAY EQUATIONS}
%An interesting question is how to construct a one-way equation
%like the downward-continuation equation
%from two-way equations given us by physics.
%Even the existence of one-way equations is a fundamental theoretical question.
%Although I have nothing to say about existence,
%if they exist, here are some ideas how to construct them.
%These ideas might be useful for exotic wavetypes.
%I include them here mainly to draw together ideas of filters
%and partial differential equations.
%\par
%Take the differencing molecule of any wave-like physical process
%like the scalar wave equation.
%This will need to be a physical process that damps out as it goes to infinity.
%Suppose the thickness of this molecule in some direction is $m$ points.
%Place on the plane random impulses separated by $m$ or more points.
%Solve the missing data problem to fill in the values
%between the random points.
%This should be the solution to the given difference equation
%in the source free regions of space between pulses.
%Given this solution plane, solve for the 2-D prediction-error filter (PEF).
%The PEF should be a one-way equation for the original physical problem.
%We could dispense with the random numbers
%and solve two stages of least squares on the wave molecule itself.
%Perhaps we can find a filter whose autocorrelation is the Laplace operator.
%The filter's phase deserves investigation.

\section{References}
\reference{\bx{Canales}, L.L., 1984,
        Random noise reduction:
        54th Ann. Internat. Mtg.,
        Soc. Explor. Geophys.,
        Expanded Abstracts, 525-527.}

\reference{\bx{Rothman}, D., 1985,
        Nonlinear inversion, statistical mechanics,
        and residual statics estimation: Geophysics, {\bf 50}, 2784-2798
        }

\reference{\bx{Spitz}, S., 1991,
        Seismic trace interpolation in the F-X domain:
        Geophysics, {\bf 56}, 785-794.
        }
\newpage

%\end{notforlecture}
