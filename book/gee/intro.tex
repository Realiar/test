\chapter*{Preface}

\begin{quote}
\emph{The difference between theory and practice is smaller in theory than it is in
  practice.} --folklore
\end{quote}

We make discoveries about reality by examining the discrepancy between
theory and practice.  There is a well-developed theory about the
difference between theory and practice, and it is called ``geophysical
inverse theory''. In this book we investigate the practice of the
difference between theory and practice. As the folklore tells us,
there is a big difference. There are already many books on the theory,
and often as not, they end in only one or a few applications in the
author's specialty. In this book on practice, we examine data and
results from many diverse applications. I have adopted the discipline
of suppressing theoretical curiosities until I find data that requires
it (except for a few concepts at chapter ends).

Books on geophysical inverse theory tend to address theoretical topics
that are little used in practice. Foremost is probability theory. In
practice, probabilities are neither observed nor derived from
observations. For more than a handful of variables, it would not be
practical to display joint probabilities, even if we had them. If you
are data poor, you might turn to probabilities. If you are data rich,
you have far too many more rewarding things to do. When you estimate a
few values, you ask about their standard deviations. When you have an
image making machine, you turn the knobs and make new images (and
invent new knobs). Another theory not needed here is singular-value
decomposition.

In writing a book on the ``practice of the difference between theory
and practice'' there is no worry to be bogged down in the details of
diverse specializations because the geophysical world has many
interesting data sets that are easily analyzed with elementary physics
and simple geometry. (My specialization, reflection seismic imaging,
has a great many less easily explained applications too.) We find here
many applications that have a great deal in common with one another,
and that commonality is not a part of common inverse theory. Many
applications draw our attention to the importance of two weighting
functions (one required for data space and the other for model
space). Solutions depend strongly on these weighting functions
(eigenvalues do too!). Where do these functions come from, from what
rationale or estimation procedure? We'll see many examples here, and
find that these functions are not merely weights but filters. Even
deeper, they are generally a combination of weights and filters.  We
do some tricky bookkeeping and bootstrapping when we filter the
multidimensional neighborhood of missing and/or suspicious data.

Are you aged 23? If so, this book is designed for you. Life has its
discontinuities: when you enter school at age 5, when you marry, when
you leave university, when you retire. The discontinuity at age 23,
mid graduate school, is when the world loses interest in your
potential to learn. Instead the world wants to know what you are
accomplishing right now! This book is about how to make images. It is
theory and programs that you can use right now.  

This book is not devoid of theory and abstraction. Indeed it makes an
important new contribution to the theory (and practice) of data
analysis: multidimensional autoregression via the helical coordinate
system.

The biggest chore in the study of ``the practice of the difference
between theory and practice'' is that we must look at algorithms. Some
of them are short and sweet, but other important algorithms are
complicated and ugly in any language. This book can be printed without
the computer programs and their surrounding paragraphs, or you can
read it without them. I suggest, however, you take a few moments to
try to read each program. If you can write in any computer language,
you should be able to read these programs well enough to grasp the
concept of each, to understand what goes in and what should come
out. I have chosen the computer language (more on this later) that I
believe is best suited for our journey through the ``elementary''
examples in geophysical image estimation.  

Besides the tutorial value of the programs, if you can read them, you
will know exactly how the many interesting illustrations in this book
were computed so you will be well equipped to move forward in your own
direction.

\section*{THANKS}

2004 is my twelfth year of working on this book and much of it comes
from earlier work and the experience of four previous books. In this
book, as in my previous books, I owe a great deal to the many students
at the Stanford Exploration Project. I would like to mention some with
particularly notable contributions (in approximate historical order).

The concept of this book began along with the PhD thesis of Jeff
Thorson. Before that, we imagers thought of our field as ``an hoc
collection of good ideas'' instead of as ``adjoints of forward
problems''. Bill Harlan understood most of the preconditioning issues
long before I did. All of us have a longstanding debt to Rick Ottolini
who built a cube movie program long before anyone else in the industry
had such a blessing.

My first book was built with a typewriter and ancient technologies. In
early days each illustration would be prepared without reusing
packaged code. In assembling my second book I found I needed to
develop common threads and code them only once and make this code
systematic and if not idiot proof, then ``idiot resistant''. My early
attempts to introduce ``seplib'' were not widely welcomed until Stew
Levin rebuilt everything making it much more robust.  My second book
was typed in the troff text language. I am indebted to Kamal Al-Yahya
who not only converted that book to \LaTeX, but who wrote a
general-purpose conversion program that became used internationally.

Early days were a total chaos of plot languages. I and all the others
at SEP are deeply indebted to Joe Dellinger who starting from work of
Dave Hale, produced our internal plot language ``vplot'' which gave us
reproducibiliy and continuity over decades. Now, for example, our
plots seamlessly may be directed to postscript (and PDF), Xwindow, or
the web. My second book required that illustrations be literally taped
onto the sheet containing the words.  All of us benefitted immensely
from the work of Steve Cole who converted Joe's vplot language to
postscript which was automatically integrated with the text.

When I began my third book I was adapting liberally from earlier
work. I began to realize the importance of being able to reproduce any
earlier calculation and began building rules and file-naming
conventions for ``reproducible research''. This would have been
impossible were it not for Dave Nichols who introduced \texttt{cake},
a variant of the UNIX software building program \texttt{make}. Martin
Karrenbach continued the construction of our invention of
``reproducible research'' and extended it to producing reproducible
research reports on CD-ROM, an idea well ahead of its time. Some
projects were fantastic for their time but had the misfortune of not
being widely adopted, ultimately becoming unsupportable. In this
catagory was Dave and Martin's implementation \texttt{xtex}, a
magnificent way of embedding reproducible research in an electronic
textbook. When \texttt{cake} suffered the same fate as \texttt{xtex},
Matthias Schwab saved us from mainstream isolation by bringing our
build procedures into the popular GNU world.

Coming to the present textbook I mention Bob Clapp. He made numerous
contributions.  When Fortran77 was replaced by Fortran90, he rewrote
Ratfor. For many years I (and many of us) depended on Ratfor as our
interface to Fortran and as a way of presenting uncluttered code. Bob
rewrote Ratfor from scratch merging it with other SEP-specific
software tools (Sat) making Ratfor90. Bob prepared the
interval-velocity examples in this book. Bob also developed most of
the ``geostat'' ideas and examples in this book. Morgan Brown
introduced the texture examples that we find so charming. Paul Sava
totally revised the book's presentation of least-squares solvers
making them more palatable to students and making more honest our
claim that in each case the results you see were produced by the code
you see.

One name needs to be singled out. Sergey Fomel converted all the
examples in this book from my original Fortran 77 to a much needed
modern style of Fortran 90. After I discovered the helix idea and its
wide-ranging utility, he adapted all the relevant examples in this
book to use it. If you read Fomel's programs, you can learn effective
application of that 1990's revolution in coding style known as
``object orientation.''

{\small This electronic book, ``Geophysical Exploration by Example,''
is free software; you can redistribute it and/or modify it under the
terms of the GNU General Public License as published by the Free
Software Foundation; either version 2 of the License, or (at your
option) any later version. This book is distributed in the hope that
it will be useful, but WITHOUT ANY WARRANTY; without even the implied
warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See
the GNU General Public License for more details. You should have
received a copy of the GNU General Public License along with this
program; if not, write to the Free Software Foundation, Inc., 675
Massachusetts Ave., Cambridge, MA 02139, USA.}

\noindent Jon Claerbout \\
\noindent April 27, 2004
