\append{Incremental DELAUNAY TRIANGULATION and related problems}

Delaunay triangulation \cite[]{delaunay2,sibson,stolfi} is a fundamental
geometric construction, which has numerous applications in different
computational problems. For a given set of nodes (points on the
plane), Delaunay triangulation constructs a triangle tessellation of
the plane with the initial nodes as vertices. Among all possible
triangulations, the Delaunay triangulation possesses optimal
properties, which make it very attractive for practical applications,
such as computational mesh generation. One of the most well-known
properties is maximizing the minimum triangulation angle. In three
dimensions, Delaunay triangulation generalizes naturally to a
tetrahedron tessellation.
\par
Several optimal-time algorithms of Delaunay triangulation (and its
counterpart--Voronoi diagram) have been proposed in the literature.
The divide-and-conquer algorithm \cite[]{shamos,stolfi} and the
sweep-line algorithm \cite[]{fortune} both achieve the optimal $O (N
\log N)$ worst-case time complexity. Alternatively, a family of
incremental algorithms has been used in practice because of their
simplicity and robustness. Though the incremental algorithm can take
$O (N^2)$ time in the worst case, the expectation time can still be $O
(N \log N)$, provided that the nodes are inserted in a random order
\cite[]{knuth}.
\par
The incremental algorithm consists of two main parts:
 \begin{enumerate}
 \item Locate a triangle (or an edge), containing the inserted point.
 \item Insert the point into the current triangulation, making the
   necessary adjustments.
 \end{enumerate}
\par
The Delaunay criterion can be reduced in the second step to a simple
\emph{InCircle} test \cite[]{stolfi}: if a circumcircle of a triangle
contains another triangulation vertex in its circumcenter, then the
edge between those two triangles should be ``flipped'' so that two new
triangles are produced. The testing is done in a recursive fashion
consistent with the incremental nature of the algorithm. When a new
node is inserted inside a triangle, three new triangles are created,
and three edges need to be tested. When the node falls on an edge,
four triangles are created, and four edges are tested. In the case of
test failure, a pair of triangles is replaced by the flip operation
with another pair, producing two more edges to test. Under the
randomization assumption, the expected total time of point insertion
is $O (N)$.  Randomization can be considered as an external part of
the algorithm, provided by preprocessing.
\par
\cite{knuth} reduce the point location step to an efficient $O (N
\log N)$ procedure by maintaining a hierarchical tree structure: all
triangles, occurring in the incremental triangulation process, are
kept in memory, associated with their ``parents.'' One or two point
location tests (\emph{CCW} tests) are sufficient to move to a lower
level of the tree. The search terminates with a current Delaunay
triangle.
\par
To test the algorithmic performance of the incremental construction, I
have profiled the execution time of my incremental triangulation
program with the Unix \texttt{pixie} utility. The profiling result,
shown in Figures~\ref{fig:itime} and~\ref{fig:ctime}, complies
remarkably with the theory: $O (N \log N)$ operations for the point
location step, and $O (N)$ operations for the point insertion step.
The experimental constant for the insertion step time is about $8.6$.
The experimental constant for the point location step is $4$.  The CPU
time, depicted in Figure~\ref{fig:time}, also shows the expected $O (N
\log N)$ behavior.

\inputdir{.}

\sideplot{itime}{width=2.5in}{The number of point insertion operations
(\emph{InCircle} test) plotted against the number of points.}

\sideplot{ctime}{width=2.5in}{Number of point location operations
  (\emph{CCW} test) plotted against the number of points.}

\sideplot{time}{width=2.5in}{CPU time (in seconds per point) plotted
  against the number of points.}
\par
A straightforward implementation of Delaunay triangulation would
provide an optimal triangulation for any given set of nodes. However,
the quality of the result for unfortunate geometrical
distributions of the nodes can be unsatisfactory. In the rest of this
appendix, I describe three problems, aimed at improving the
triangulation quality: conforming triangulation, triangulation of
height fields, and mesh refinement.  Each of these problems can be
solved with a variation of the incremental algorithm.

\subsection{Conforming Triangulation}

\inputdir{tri}

In the practice of mesh generation, the input nodes are often
supplemented by boundary edges: geologic interfaces, seismic rays, and
so on. It is often desirable to preserve the edges so that they appear
as edges of the triangulation \cite[]{SEG-1994-0502}. One possible approach is
\emph{constrained} triangulation, which preserves the edges, but only
approximately satisfies the Delaunay criterion \cite[]{lee,chew}. An
alternative, less investigated, approach is \emph{conforming}
triangulation, which preserves the ``Delaunayhood'' of the
triangulation by adding additional nodes \cite[]{hansen} (Figure
\ref{fig:conform}).  Conforming Delaunay triangulations are difficult
to analyze because of the variable number of additional nodes. This
problem was attacked by \cite{edels}, who suggested an algorithm
with a defined upper bound on added points. Unfortunately,
Edelsbrunner's algorithm is slow in practice because the number of
added points is largely overestimated.  I chose to implement a
modification of the simple incremental algorithm of Hansen and Levin.
Although Hansen's algorithm has only a heuristic justification and
sets no upper bound on the number of inserted nodes, its simplicity is
attractive for practical implementations, where it can be easily
linked with the incremental algorithm of Delaunay triangulation.
\par
The incremental solution to the problem of conforming triangulation
can be described by the following scheme:
 \begin{itemize}
 \item First, the boundary nodes are triangulated.
 \item Boundary edges are inserted incrementally.
 \item If a boundary edge is not present in the triangulations, it is
   split in half, and the middle node is inserted into the triangulation. This
   operation is repeated for the two parts of the original boundary
   edge and continues recursively until all the edge parts 
   conform.
 \item If at some point during the incremental process, a boundary edge
   violates the Delaunay criterion (the \emph{InCircle} test), it is
   split to assure the conformity.
 \end{itemize}

\plot{conform}{width=4in,height=2in}{An illustration of conforming triangulation.
  The left plot shows a triangulation of 500 random points; the
  triangulation in the right plot is conforming to the embedded
  boundary.  Conforming triangulation is a genuine Delaunay
  triangulation, created by adding additional nodes to the original
  distribution.}
\par
To insert an edge $AB$ into the current triangulation, I use the
following recursive algorithm:
 \begin{quote}
 Function \textbf{InsertEdge} ($AB$)
 \begin{enumerate}
 \item Define $C$ to be the midpoint of $AB$.
 \item Using the triangle tree structure, locate triangle $\mathcal{T} = DEF$
   that contains $C$ in the current triangulation.
 \item \textbf{If} $AB$ is an edge of $\mathcal{T}$ \textbf{then return}.
 \item \textbf{If} $A$ (or $B$) is a vertex of $\mathcal{T}$ (for example, $A = D$)
   {\bf then} define $C$ as an intersection of $AB$ and $EF$.
 \item {\bf Else} define $C$ as an intersection of $AB$ and an
   arbitrary edge of $\mathcal{T}$ (if such an intersection exists).
 \item Insert $C$ into the triangulation.
 \item {\bf InsertEdge} ($CA$).
 \item {\bf InsertEdge} ($CB$).
 \end{enumerate}
 \end{quote}
\par
The intersection point  of edges $AB$ and $EF$ is given by the formula
\begin{equation}
  C = A + \lambda (B-A)\;,
\end{equation}
where
\begin{equation}
  \lambda = \frac{(F_y - E_y)\,(E_x - A_x) - (F_x - E_x)\,(E_y-A_y)}{
    \det \left|\begin{array}{cc}
        B_x - A_x & B_y - A_y \\
        F_x - E_x & F_y - E_y
    \end{array}\right|}\;.
\end{equation}
The value of $\lambda$ should range between $0$ and $1$.
\par
If, at some stage of the incremental construction, a boundary edge
$AB$ fails the Delaunay \emph{InCircle} test for the circle $CABD$,
then I simply split it into two edges by adding the point of
intersection into the triangulation.  The rest of the process is very
much like the process of edge validation in the original incremental
algorithm.

\subsection{Triangulation of Height Fields}

Often, a velocity field (or other object that we want to triangulate)
is defined on a regular Cartesian grid. One way to perform a
triangulation in this case is to select a smaller subset of the
initial grid points, using them as the input to a triangulation
program. We need to select the points in a way that preserves the main
features of the original image, while removing some unnecessary
redundancy in the regular grid description.

\plot{sphere}{width=6in,height=2in}{Illustration of Garland's
  algorithm for triangulation of height fields. The left plot shows
  the input image of a sphere, containing 100 by 100 pixels. The
  middle plot shows 500 pixels, selected by the algorithm and
  triangulated. The right plot is the result of local plane
  interpolation of the triangulated surface.}
\par
\cite{height} surveyed different approaches
to this problem and proposed a fast version of the incremental
\emph{greedy insertion} algorithm. Their algorithm adds points
incrementally, selecting at each step the point with the maximum
interpolation error with respect to the current triangulation. Though
a straightforward implementation of this idea would lead to an
unacceptably slow algorithm, Garland and Heckbert have discovered
several sources for speeding it up. First, we can take advantage of
the fact that only a small area of the current triangulation gets
updated at each step. Therefore, it is sufficient to recompute the
interpolation error only inside this area. Second, the maximum
extraction procedure can be implemented very efficiently with a
priority queue data structure.

\inputdir{.}

\sideplot{opengl}{width=2in,height=2in}{An image from the previous
  example, as rendered by the OpenGL library. The shades on polygonal
  (triangulated) sides are exaggerated by a simulation of the direct
  light source.}
\par
Figure \ref{fig:sphere} illustrates this algorithm with a simple
example. The original image (the left plot) contained 10,000 points,
laid out on a regular rectangular grid. The algorithm selects a
smaller number of points and immediately triangulates them (the middle
plot).  The image can be reconstructed by local plane interpolation
(the right plot.) The reconstruction quality can be further improved
by increasing the number of triangles. Figure \ref{fig:opengl} shows
the same image as rendered by the OpenGL graphics library
\cite[]{opengl}.

\inputdir{tri}

\plot{marmousi}{width=6in}{Applying the height triangulation algorithm
  to the Marmousi model. The left plot shows a smoothed and windowed
  version of the Marmousi model. The middle plot is a result of
  10,000-point triangulation, followed by linear interpolation. The
  right plot shows the difference between the two images.}
\par
Figure \ref{fig:marmousi} shows an application of the height
triangulation algorithm to the famous Marmousi model. The left plot
shows a smoothed and windowed version of the Marmousi, plotted on a
501 by 376 computational grid. In the middle plot, 10,000 points from
the original 188,376 were selected for triangulation and interpolated
back to the rectangular grid. The right plot demonstates the small
difference between the two images.

\subsection{Mesh Refinement}

One the main properties of Delaunay triangulation is that, for a
given set of nodes, it provides the maximum smallest angle among
all possible triangulations. It is this property that supports the wide
usage of Delaunay algorithms in the mesh generation problems.
However, it doesn't guarantee that the smallest angle will always be small.
In fact, for some point distributions, it is impossible to avoid
skinny small-angle triangles. The remedy is to add additional
nodes to the triangulation so that the quality of the triangles is
globally improved. This problem has become known as
\emph{mesh refinement} \cite[]{ruppert}.

\plot{hole}{width=6in,height=1.5in}{An illustration of Rivara's
  refinement algorithm. The left plot shows an input to the algorithm:
  a valid Delaunay triangulation with ``skinny'' triangles. Two
  other plots show successive applications of the refinement
  algorithm.}
\par
One of the recently proposed mesh refinement algorithms is Rivara's
\emph{backward longest-side refinement} technique \cite[]{rivara}.  The
main idea of the algorithm is to trace the LSPP (longest-side
propagation path) for each refined triangle. The LSPP is an ordered
list of triangles, connected by a common edge, such that the longest
triangle edge is strictly increasing. After tracing the LSPP, we
bisect the longest edge and insert its midpoint into the
triangulation. Rivara's algorithm is remarkably efficient and easy to
implement. In comparison with alternative methods, it has the
additional advantage of being applicable in three dimensions.
\par
Figure \ref{fig:cerveny} demonstrates an application of different
triangulation techniques to a simple layered model, borrowed from the
Seismic Unix demos (where it is attributed it to V.\v{C}erven\'{y}.)
Another model from \cite{hale} is used in Figure \ref{fig:susalt}.

\plot{cerveny}{width=6in,height=4in}{A comparison of different
  triangulation techniques on a simple layered model. The top left
  plot shows the original model; the top right plot, the result of
  noncomforming triangulation; the two bottom plots, conforming
  triangulation and an additional mesh refinement.}

\plot{susalt}{width=6in,height=4in}{A comparison of different
  triangulation techniques on a simple salt-type model. The top left
  plot shows the original model; the top right plot, the result of
  noncomforming triangulation; the two bottom plots, conforming
  triangulation and an additional two-step mesh refinement.}

\subsection{Implementation Details}
Edge operations form the basis of the incremental algorithm.
Therefore, it is convenient to describe triangulation with
edge-oriented data structures \cite[]{stolfi}. I have followed the idea
of \cite{hansen} of associating with each edge two pointers to the
end points and two pointers to the adjacent triangles.  The triangle
structure is defined by three pointers to the edges of a triangle.
Additionally, as required by the point location algorithm, each
triangle has a pointer to its ``children.'' This pointer is NULL when
the triangle belongs to the current Delaunay triangulation.
\par
Many researchers have pointed out that the geometric
primitives used in triangulation must be robust with respect to
round-off errors of finite-precision calculation. To assure the
robustness of the code, I used the adaptive-precision predicates of
\cite{shewchuk}, available as a separate package from the
\texttt{netlib} public-domain archive.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
