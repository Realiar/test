\def\figdir{./Fig} 
\lefthead{Rickett \& Claerbout}
\righthead{Factoring the Helmholtz equation}
\footer{SEP--97}
\keywords{helix, wave equation, depth-migration}

\title{Helical factorization of the {H}elmholtz equation}

\email{james@sep.stanford.edu, jon@sep.stanford.edu}
\author{James Rickett and Jon Claerbout}

\ABS{
The accuracy of conventional explicit wavefield extrapolation
algorithms at high dips is directly related to the length of the
convolution filters: increasing the dip range leads to increased cost.
Recursive filters have the advantage over convolutional filters in
that short filters can move energy long distances. 
We discard both Crank-Nicolson and McClellan transforms, and
extrapolate waves by factoring the 3-D Helmholtz equation in a helical
coordinate system.
We show that one of the minimum-phase factors provides a 90$^\circ$
extrapolator, that can be applied recursively in the ($\omega-{\bf x})$
domain. 
By developing a purely recursive wavefield
extrapolator, we hope to achieve accuracy at high dips with
shorter filters than is possible with explicit methods.
}

\section{Introduction}
Depth migration algorithms are important for imaging in areas with
strong lateral velocity gradients. Wavefield extrapolation algorithms
in the $(\omega-{\bf x})$ domain have the advantage over Kirchhoff depth
migration methods that they are based on finite bandwidth solutions to
the wave-equation not asymptotic approximations. Additionally, they
have the advantage over $(\omega-{\bf k})$ methods that they can easily
handle lateral velocity variations in a single migration.

\par
Claerbout \shortcite{iei} describes implicit 2-D wavefield
extrapolation based on the Crank-Nicolson formulation.  This rational
operator is unitary, and so represents a pure
phase-shift. Unfortunately, however, the simple extension to 3-D leads
to prohibitive computational complexity. 

\par
In practice, wavefield extrapolation in 3-D is usually accomplished
with explicit operators and McClellan transforms
\cite{hale90b,hale90a}. Unfortunately again, 
however, accuracy at high dips (large spatial wavenumbers) can only be
achieved with long explicit filters.

\par
In this paper, we construct a finite-difference approximation to the
Helmholtz operator in the $(\omega-{\bf x})$ domain. The helical
coordinate system allows us to remap the multi-dimensional operator
into one-dimensional space, where we can find two minimum-phase
factors using a conventional spectral factorization algorithm.

\par
Each minimum-phase factor provides a recursive filter that we can use
to extrapolate the wavefield in depth.
Recursive filters move energy longer distances than explicit filters
of the same length. By developing a purely recursive wavefield
extrapolator, the hope is to achieve accuracy at high dips with
shorter filters than is possible with explicit methods.

\section{Poisson's equation}
\inputdir{lapfac}
As a simple illustration of how helical boundary conditions can lead
to recursive solutions to partial differential equations, we consider
Poisson's equation, which relates potential, $u$, to source density,
$f$, through the Laplacian operator:
\begin{equation}
\nabla^2 u = f(x,y,z)
\end{equation}
Poisson's equation crops up in many different branches of physics: for
example, in electrostatics, gravity, fluid dynamics (where the fluids
are incompressible and irrotational), and steady-state temperature
studies.  It also serves as a simple analogue to the wave-propagation
equations which provide the main interest of this paper.

\par
To solve Poisson's equation on a regular grid
\cite{Claerbout.sep.95.jon1}, we can approximate the 
Laplacian by a convolution with a small finite-difference filter.
Taking the operator, ${\bf D}$, to represent convolution with filter,
$d$, Poisson's equation becomes
\begin{equation}
{\bf D \; u}={\bf f}.
\end{equation}
Although ${\bf D}$ itself is a multi-dimensional convolution operator
that is not easily invertible, helical boundary
conditions~\cite{Claerbout.sep.95.jon1} allow us to reduce the
dimensionality of the convolution to an equivalent one-dimensional
filter, which we can factor into the product of a lower-triangular
matrix, ${\bf L}$, and its transpose, ${\bf L}^T$. These triangular
matrices represent causal and anti-causal convolution with a
minimum-phase filter, in the form
\begin{equation}
{\bf D \; u}={\bf L}^T \; {\bf L} \; {\bf u}={\bf f}.
\end{equation}
We can then calculate $u$ directly since ${\bf L}$ and its transpose
are easily invertible by recursive polynomial division:
\begin{equation}
{\bf u} = {\bf L}^{-1} \; ({\bf L}^T)^{-1} \; {\bf f}.
\end{equation}
\plot{lapfac}{width=6in,height=2.0in} { 
Deconvolution by a filter whose autocorrelation
is the two-dimensional Laplacian operator.
This amounts to solving the Poisson equation.
After~\longcite{Claerbout.sep.95.jon1}.
}

\section{The Helmholtz equation}
\inputdir{wavemovie}

Starting from the full wave equation in three-dimensions:
\begin{equation}
-\nabla^2 p + \frac{1}{v^2} \frac{\partial^2 p}{\partial t^2}=0
\end{equation}
we can Fourier transform the time axis, and look for $(\omega, {\bf x}$)
solutions of the form:
\begin{equation}
p(\omega,{\bf x}) = q ({\bf x}) \; e^{-i \omega t}
\end{equation}
For a single frequency, the wave equation therefore reduces to the
Helmholtz (time-independent diffusion) equation
\begin{equation} \label{eqn:helmholtz}
\left(-\nabla^2 - \alpha^2\right) q({\bf x})=0
\end{equation}
where $\alpha=\omega/v$.

\par
We aim to factor this equation on a helix, as with the Poisson
equation above.  However, before we can, we need to ensure
that it is a `level-phase' function~\cite{Claerbout.sep.97.jon1}, that
is to say the spectrum of the operator does not touch the negative
real axis on the complex plane.  
The spectrum of the Helmholtz operator can be obtained by taking the
Fourier transform of equation~(\ref{eqn:helmholtz}).
\begin{equation}
S({\bf k}) = |{\bf k}|^2 - \alpha^2 
\end{equation} 

\par
$S({\bf k})$ clearly becomes negative real for small
values of $| {\bf k} |$; so as it stands, this equation is not
factorable. Fortunately, however,  replacing $\alpha$ by $\alpha'=
\alpha-\epsilon / i$, where $\epsilon$ is a small positive number,
successfully stabilizes the spectrum, by pushing the function off the
negative real axis.  The physical effect of $\epsilon$ is to provide
damping as the wave propagates, differentiating between the forward
and backward extrapolation directions.

\par
Before factorization, equation~(\ref{eqn:helmholtz}) should therefore
be rewritten to include the stabilization term
\begin{equation} \label{eqn:singlefdamp}
\left[ -\nabla^2 + (-i \alpha + \epsilon)^2 \right] q({\bf x}) = 
\left( -\nabla^2 - \alpha'^2 \right) q({\bf x}) = 0
\end{equation} 

\par
Following the helix solution to Poisson's equation above, a simple 
finite-difference approximation to the Laplacian, $-\nabla^2 \approx
{\bf D}$, produces the matrix equation: 
\begin{equation}
\left( {\bf D} - \alpha'^2 {\bf I} \right) {\bf q} = {\bf 0}  
\end{equation}
Alternatively, and more accurately, we can form a rational
approximation to the Laplacian operator,
\begin{equation} \label{eqn:sixth}
-\nabla^2 \approx \frac{\bf D}{{\bf I} + \beta {\bf D}}
\end{equation}
where $\beta \; (\approx 1/6)$ is Claerbout's \shortcite{iei} adjustable
`one-sixth' parameter, and 
${\bf D}$ again represents convolution with a simple finite-difference
filter, $d$. 

\par
Inserting equation~(\ref{eqn:sixth}) into
equation~(\ref{eqn:singlefdamp}) yields a matrix equation of
similar form, but with increased accuracy at high spatial wavenumbers: 
\begin{eqnarray} 
\left( \frac{\bf D}{{\bf I} + \beta {\bf D}} - \alpha'^2 {\bf I}
\right) {\bf q} & = & {\bf 0} \\ 
\left[ ( 1 - \alpha'^2 \beta ) {\bf D} -
\alpha'^2 {\bf I} \right] {\bf q}  =  {\bf H} \; {\bf q} & = & {\bf 0}
\label{eqn:matsixth}
\end{eqnarray}

\par
The operator on the left-hand-side of equation~(\ref{eqn:matsixth})
represents a three-dimensional convolution matrix, that can be mapped
to an equivalent one-dimensional convolution by applying helical
boundary conditions.
Although the complex $\alpha'$ coefficients on the main diagonal cause
the matrix not to be Hermitian, the spectrum of the matrix 
is of level-phase. Therefore, for constant $\alpha'$, it can be
factored into causal and anti-causal (triangular) components with any
spectral factorization algorithm that has been adapted for
cross-spectra \cite{Claerbout.sep.97.jon1}. 
\begin{equation} \label{eqn:helmfac}
{\bf H} \; {\bf q} = {\bf U L} \; {\bf q} =  {\bf 0}
\end{equation}

\par
The challenge of extrapolation is to find ${\bf q}$ that
satisfies both the above equation and our initial conditions,
${\bf q}_{z=0}$. Starting from ${\bf q}_{z=0}$, we can invert ${\bf
L}$ recursively to obtain a function that satisfies both the
initial conditions, and 
\begin{equation}
{\bf L} \; {\bf q} =  {\bf 0}.
\end{equation}
Hence ${\bf q}$ will also satisfy equation~(\ref{eqn:helmfac}).

\section{Wave extrapolation}
The basis for wavefield extrapolation is an operator, $W(k)$, that
marches the wavefield $q$, at depth $z$, down to depth $z+1$.
\begin{equation} \label{eqn:extrap}
q_{z+1}=W \; q_{z}.
\end{equation}
Ideally, $W({\bf k})$, will have the form of the phase-shift
operator~\cite{gazdag78},
\begin{equation} \label{eqn:gazdag}
%%{\rm Gazdag:} \hspace{.75in} 
W({\bf k})=e^{i \sqrt{\alpha^2-|{\bf k}|^2}}.
\end{equation}

\par
Due to lateral velocity variations, and the desire to avoid spatial
Fourier transforms, approximations to $W({\bf k})$ are often applied
in the $(\omega-{\bf x})$ domain. 
Typically $W({\bf k})$ is split into a `thin-lens' term that propagates the
wave vertically, and a `diffraction' term that models more complex
wave phenomena.  In the $(\omega-{\bf x})$ domain, the thin-lens term
can be applied as a simple phase-shift, while the diffraction term is
approximated by a small finite-difference filter.  The method of
extrapolation determines the nature of the finite-difference
filter. 
The mathematical forms of different extrapolators are summarized in
Table~1, and discussed below.
\begin{table} \begin{center}
\begin{tabular}{||ll||} \hline
Gazdag:   & $W({\bf k}) = e^{i \sqrt{\alpha^2-|{\bf k}|^2}}$
\rule[-.3cm]{0cm}{.9cm} \\ 
Implicit: & $W({\bf k}) = e^{i\alpha} \;
\frac{A({\bf k})}{B({\bf k})}$  
\rule[-.3cm]{0cm}{.9cm} \\
Implicit with helical factorization: & $W({\bf k}) = e^{i\alpha} \; 
\frac{U_A({\bf k}) L_A({\bf k})}{U_B({\bf k})L_B({\bf k})}$  
\rule[-.3cm]{0cm}{.9cm}  \\ 
Explicit: & $W({\bf k}) = e^{i\alpha} \; C({\bf k})$ 
\rule[-.3cm]{0cm}{.9cm} \\
Helmholtz factorization: & $W({\bf k}) =  \frac{1}{L({\bf k})}$
\rule[-.3cm]{0cm}{.9cm} \\ \hline
\end{tabular} \end{center}
\caption{Comparison of the mathematical form of various wavefield
extrapolators} 
\end{table}

\par
Implicit extrapolation approximates $W({\bf k})$ with a rational form,
consisting of a convolutional filter, and an inverse filter.
The traditional Crank-Nicolson implicit formulation ensures the pair
of convolutional operators, $A({\bf k})$ and $B({\bf k})$, are complex
conjugates, and so the resulting extrapolator is unitary. 
Implicit methods apply an extrapolator of the form
\begin{equation} \label{eqn:impextrap}
W({\bf k})=e^{i\alpha} \;\frac{A({\bf k})}{B({\bf k})}.
\end{equation}

\par
Although implicit extrapolation is often the method of choice in 2-D, 
unfortunately the cost of the matrix inversion means traditional
implicit extrapolation is rarely possible in 3-D.
Helical boundary conditions facilitate 3-D implicit methods by
providing a way to decompose the filters into an upper and lower
triangular pair, which can be easily inverted
\cite{Rickett.sep.97.james1}.  
The extrapolator in equation~(\ref{eqn:impextrap}), therefore, becomes
\begin{equation}
%%{\rm Implicit \; with \; helical \; factorization:} \hspace{.25in}
W({\bf k})=e^{i\alpha} \; 
\frac{U_A({\bf k}) L_A({\bf k})}{U_B({\bf k})L_B({\bf k})}.
\end{equation}

\par
Most practical 3-D extrapolation is done with an explicit operator,
using McClellan transforms. This approach amounts to approximating
$W({\bf k})$ by with a simple convolutional filter, $C({\bf k})$.
Explicit extrapolators, therefore, have the form
\begin{equation}
%%{\rm Explicit:} \hspace{.75in} 
W({\bf k})=e^{i\alpha} \; C({\bf k}).
\end{equation}

\par
In contrast to these methods, the minimum-phase factorization of the
Helmholtz equation provides appears to provide a recursive depth
extrapolator of the different form
\begin{equation} \label{eqn:helmextrap}
%%{\rm Helmholtz \; factorization:} \hspace{.5in}
W({\bf k})=\frac{1}{L({\bf k})},
\end{equation}
where $L({\bf k})$ is a minimum-phase filter.  

\par
The inverse of the Helmholtz factorization, therefore, is all poles
and no zeros. 
%%However, the lead coefficient
%%of the $L({\bf k})$ will be complex, and we can easily (and
%%arbitrarily) rewrite the extrapolator as
%%\begin{equation}
%%{\rm Helmholtz \; factorization:} \hspace{.5in}
%%W({\bf k})=e^{i\alpha} \frac{1}{L'({\bf k})}
%%\end{equation}
However, the apparent contradiction that we are approximating the
unitary operator in equation~(\ref{eqn:gazdag}) with the minimum-phase
extrapolator in equation~(\ref{eqn:helmextrap}) is resolved by
examining the impulse response of the operator $\frac{1}{L({\bf
k})}$ shown in Figure~\ref{fig:impresp}. The inverse of the factor is
indeed minimum-phase if you consider the response at depths~$z$
and~$z+1$. However, we are only interested in the response at depth
step $z+1$, i.e. the second bump in the lower panel of
Figure~\ref{fig:impresp}, which is symmetric and tapers to zero away
from the location of the impulse.
We are not concerned by the first bump on
the lower panel of Figure~\ref{fig:impresp}, as this corresponds to
the response of the filter at depth step~$z$.
\sideplot{impresp}{width=3.5 in}{Amplitude of impulse response of 
polynomial division with minimum-phase factorization of the Helmholtz
equation. The top panel shows the location of the impulse. The bottom
panel shows the impulse response.  Helical boundary conditions mean
the second bump in the impulse response corresponds to energy
propagating to the next depth step.}

\subsection{Propagating waves with the {\tt Wavemovie} program}
The following pseudo-code provides an algorithm for propagating waves
into the Earth with the the new factorization of the wave
equation. 
\begin{verbatim}
Fourier Transform input data
Loop over frequency {
     Initialize wave at z=0
     Factor wave equation for this w/v
     Recursively divide input data by factor
     Fourier Transform back to time-domain
     Sum into output
}
\end{verbatim}
Incorporating this code into the {\tt Wavemovie}
program~\cite{iei} provides a laboratory for testing the new
algorithm. 

\par
Figure~\ref{fig:vs45} compares the results of the new extrapolation
procedure with the conventional Crank-Nicolson solution to the
45$^\circ$ equation. The new approach has little dispersion since we
are using a rational approximation (the `one-sixth trick') to the
Laplacian on the vertical and horizontal axes.  In addition, the new
factorization retains accuracy up to 90$^\circ$. The high dip,
evanescent energy in the 45$^\circ$ movie, propagates correctly in the
new approach.
\sideplot{vs45}{width=3in}{Comparison of the 45$^\circ$ wave equation
(left) with the helical factorization of the Helmholtz equation
(right).} 

\par
Figure~\ref{fig:sixth} compares different value of the `one-sixth'
parameter, $\beta$.  For this application, the optimal value seems to
be $\beta=1/12$.
\plot{sixth}{width=6in}{Helmholtz equation factorization with
different values for the `one-sixth' parameter, $\beta$. From left,
$\beta =$ 0, 1/12, 1/8 and 1/6.}

\par
Figure~\ref{fig:laplac} compares different $3 \times 3$
finite-difference filters. $\gamma=0$ corresponds to the conventional
5-point filter, while $\gamma=0$ corresponds to a rotated 5-point
filter.  Values in the range $0 < \gamma < 1$ correspond to 9-point
filters that are linear combinations of the above.  Best results are
obtained with $\gamma = 2/3$.  The impulse response with $\gamma=0$
only contains energy on every second grid point, since the rotated
filter only propagates energy diagonally: as in the game of a chess,
if a bishop starts on a white square, it always stays on white.
\plot{laplac}{width=6in}{Helmholtz equation factorization with
different $3 \times 3$ finite-difference representations of the
Laplacian. From left, $\gamma =$ 0, 1/2, 2/3 and 1.}

\section{Reducing the filter length}
Although mostly zeros, the 9-point filter we factorize in 2-D 
is actually $2 N_x+3$ points long on a helix, and so its two
factors each contain $N_x+2$ points.
For Figures~\ref{fig:vs45},~\ref{fig:sixth} and~\ref{fig:laplac}
above, we did not discard any of these filter coefficients: 
our recursive filters contained the full 128 coefficients. 
For this extrapolator to compete effectively with other methods
(especially in 3-D problems), the number of filter coefficients has 
to be reduced significantly.

\par
The factor coefficients themselves should be independent of the
diameter of the helix. This leads us to expect many zero value
coefficients on the helix `backside'.  Fortunately this is observed in
practice, and the filter coefficient amplitude drops rapidly from
either end.

\par
Unfortunately, however, the operator that we factor has roots very
close to the unit circle in the complex plane. 
The Laplacian already has a pair of roots at $Z=0$, and the effect of
the extra $\alpha^2$ term on the main diagonal is to destabilize the
operator further.  The damping rescues us in theory, but in
practice we still encounter numerical problems depending on the
factorization algorithm, and the two factors are barely
minimum-phase.  

\par
At the time of this report, we have been using the Fourier-domain
Kolmogoroff method \cite{kolmog, Claerbout.sep.97.jon1} to factor the
Helmholtz equation.   
The Kolmogoroff method has two main problems, both due to the
proximity of the roots to the unit circle. Firstly, circular boundary
conditions require us to pad the cross-correlation function before
transforming it to the Fourier domain. With the roots close to the
unit circle, extreme amounts of padding are needed: in the 2-D
examples above, we need to pad the filters to over 4,000 times their
original length.  
Secondly, the Kolmogoroff method simultaneously computes all the
filter coefficients. With roots so close to the unit circle,
truncating filter coefficients, even in a reasonable manner, often
leads to non-minimum-phase filters and divergent results. 

\par
The Wilson-Burg algorithm \cite{wilson, Sava.sep.97.paul1} may 
eventually overcome these problems. By working in the time domain, the
algorithm avoids circular boundary conditions, and the number of
filter coefficients can be defined at each iteration, providing a
best-fit filter with a given number of coefficients.
However, the Wilson-Burg algorithm also encounters problems with roots
close to the unit circle.  Specifically, numerical problems cause
filters to lose their minimum-phase nature, causing the algorithm to
diverge.  With roots very close to the unit circle, this can happen
within the first couple of iterations, so even the best result before
divergence starts may be unusable.

\section{Conclusions}
We have shown that the minimum-phase helical factorization of the
Helmholtz equation can be applied recursively to extrapolate waves up
to 90$^\circ$. The hope is that a recursive extrapolator may image
steeper dips than an explicit extrapolator with the same cost. 
Unfortunately, however, technical problems related to
the factoring of functions with roots near the unit circle, are
currently preventing this method from competing effectively with 
conventional extrapolation algorithms.

\bibliographystyle{seg}
\bibliography{SEP2,3dwave}




